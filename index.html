<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>MR.C</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Personal notes">
<meta property="og:type" content="website">
<meta property="og:title" content="MR.C">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="MR.C">
<meta property="og:description" content="Personal notes">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MR.C">
<meta name="twitter:description" content="Personal notes">
  
    <link rel="alternate" href="/atom.xml" title="MR.C" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">MR.C</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-NLP" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/04/14/NLP/" class="article-date">
  <time datetime="2021-04-14T09:26:06.000Z" itemprop="datePublished">2021-04-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/04/14/NLP/">NLP</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h5 id="Natural-Language-Processing"><a href="#Natural-Language-Processing" class="headerlink" title="Natural Language Processing"></a>Natural Language Processing</h5><ul>
<li><p>word embedding 发展历程</p>
<ul>
<li>基于字典组成one-hot模型<ul>
<li>一方面词典的数目一般都是上万数量级的，造成对于单个词而言，向量表示过于稀疏</li>
<li>另一方面由于仅仅存储0、1数据，没有办法保存对应的<strong>语序信息</strong>，也就无法通过one-hot编码挖掘词与词之间的语义关系</li>
</ul>
</li>
<li>tf-idf<ul>
<li>tf是词频，也就是当前词在文档中出现的次数</li>
<li>idf的计算方法是log(语料库中总文档数 / 包含当前词的文档数)</li>
<li>tf-idf就是one-hot的一种优化</li>
<li>文档比较有<strong>代表性的词</strong>发挥更大的作用，规避常见词（the, I, is, …）</li>
<li>无法考虑词的位置信息，上下文信息以及一些分布特征</li>
</ul>
</li>
<li>Encoder-Decoder（少用）<ul>
<li>encoder输入onehot，deocder输出</li>
</ul>
</li>
<li>NNLM（Nerual Network Language Model）<ul>
<li>基于上下文，上文预测下文</li>
<li>词向量只是副产物</li>
</ul>
</li>
<li><font color="red">word2vec</font><ul>
<li>Continuous Bag-of-Word CBOW 上下文来预测当前词（用得更多，bert也类似）<ul>
<li>计算量大（利用huffman结构，词频高的在树的浅层、词频低的在深层，减少softmax计算量）</li>
<li>负采样：找些错误样本，在正确样本学习时排斥错误样本</li>
</ul>
</li>
<li>Continuous Skip-gram 当前词来预测上下文（太难了）</li>
<li>缺点：没有解决一词多义的问题</li>
</ul>
</li>
<li>Glove (Global Vectors for Word Representation)<ul>
<li>类似word2vec，但是上下文的范围更广，是全局的句子单词</li>
<li>因为要全部文本，所以无法online training，因此用的比较少，效果并没有比word2vec太好</li>
<li>缺点：没有解决一词多义的问题</li>
</ul>
</li>
<li>Fasttext<ul>
<li>将单词拆成字符作为输入，并且利用n-gram（apple -&gt; app, ppl, ple），学习到一个embedding（embedding最终做个分类任务）</li>
<li>对于低频词生成的词向量效果会更好</li>
<li>缺点：没有解决一词多义的问题</li>
</ul>
</li>
<li>为了解决<font color="red">一词多义</font>的问题才有后面预训练模型的学习<ul>
<li>ELMO、BERT</li>
</ul>
</li>
</ul>
</li>
<li><p>Model</p>
<ul>
<li>seq-to-class<ul>
<li>输入所有token，输出一个class</li>
<li>输入所有token，对应token各输出一个class（识别句子中所有词汇的词性，word segmentation）（bert里面可以学习该两项特性，未必需要模型预先学习这些处理）</li>
</ul>
</li>
<li>seq-to-seq<ul>
<li>autoencoder+attention</li>
</ul>
</li>
<li>multiple sequences<ul>
<li>两个句子分别输入同一模型，再拼接结果</li>
<li>类似bert，用特定符号连接句子，作为一个输入</li>
</ul>
</li>
</ul>
</li>
<li><p>Task</p>
<ul>
<li>word segmentation 断词<ul>
<li>对于英文，word之间用空格分开</li>
<li>对于中文，台湾大学简陈台大 -&gt; (台湾大学)(简陈)(台大) （具体如何划分，看任务）</li>
</ul>
</li>
<li>coreference resolution 指代消解<ul>
<li>哪些词汇指向相同的东西（主语&lt;-&gt;代词）</li>
</ul>
</li>
<li>summarization 总结文本<ul>
<li>extractive summarization 提取摘要，每个句子都需要个label，模型识别哪些句子应当放入摘要（原句），作为总结整个文本</li>
<li>abstractive summarization 模型输出语句总结文本，seq-to-seq模型，并非输出原句，但会有共有的词汇（需要模型对输入词汇有拷贝作用，拷贝重要词汇作用于输入）</li>
</ul>
</li>
<li>machine translation 机器翻译<ul>
<li>seq-to-seq模型（输入语言，输出另外语言）（输入语音，输出文字）（输入一种语言的语音，输出另外语言的语音）</li>
</ul>
</li>
<li>grammar error correction 语法错误纠正<ul>
<li>seq-to-seq模型（修改语法）</li>
</ul>
</li>
<li>sentiment classification 情感分析<ul>
<li>seq-to-class模型（输入评论，输出正负情感）</li>
</ul>
</li>
<li>veracity prediction 立场预测<ul>
<li>seq-to-class模型（输入post文、评论回应等，输入正反立场）</li>
</ul>
</li>
<li>natural language inference (NLI) 自然语言推理<ul>
<li>seq-to-class模型（输入premise、hypothesis句子，输出三个类别:contradiction、entailment、neutral）</li>
<li>两个句子的关系</li>
</ul>
</li>
<li>search engine 搜索引擎<ul>
<li>seq-to-class模型（匹配问题答案的相关性，relevant）</li>
</ul>
</li>
<li><strong>QA问答</strong><ul>
<li>（Watson模型）问题处理 - 生成候选答案 - 候选答案评分 - 排序</li>
<li>阅读理解：输入question和knowledge source（unstructured documents，可以来源于搜索引擎），过滤掉不相关的documents， 输出答案</li>
</ul>
</li>
<li><strong>dialogue 对话模型</strong><ul>
<li>chatting 尬聊，需要输入历史对话，得到下一次的回复（模型应当加入更多特性：personality个性化、empathy同理心、knowledge知识丰富的）</li>
<li>task-oriented 任务导向：引导用于完成一个任务（拆分模型：natural language generation (NLG) 提前设定好可以问的问题，需要输入历史对话 -&gt; NLG -&gt; 得到下一次的回复）</li>
<li>natural language understanding (NLU) -&gt; state tracker -&gt; state -&gt; policy -&gt; NLG -&gt; answer</li>
<li>NLU: intent classification + slot filling（内容识别，提取内容）</li>
</ul>
</li>
<li><strong>knowledge graph 知识图谱</strong><ul>
<li>node 为 entity 实体， edge 为 node之间的关系</li>
<li><font color="red">从文字抽取实体、实体关系</font></li>
<li>name entity recognition (NER)<ul>
<li>根据任务确定实体范围，一般为人名、组织、地名、时间</li>
<li>seq-to-class</li>
<li>多个名字指向同一个东西，多个东西指向同一个名字，name entity linking</li>
</ul>
</li>
<li>relation extraction<ul>
<li>若relation是有限的，那么可以看成分类任务</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>pretrain + fine-tune (用大量预料做预训练，再针对特定任务的数据微调模型)</p>
<ul>
<li>What is pretrian model?<ul>
<li>each token -&gt; embedding <ul>
<li><font color="red">(old method (**word2vec and Glove**): same token -> same embedding, exclude context)</font></li>
<li>english word -&gt; token : too much words (FastText: 将单词拆成字符作为输入，学习到一个embedding)</li>
<li>chinese character -&gt; token (EMNLP: 将汉字看为图片，用CNN学习汉字各个部位，得到embedding)</li>
</ul>
</li>
<li><font color="red">Contextualized Word Emnedding </font>(基于上下文来学习单词的embedding) (学习token到一词多义)<ul>
<li>LSTM, self-attention, tree-base (少用，没有LSTM厉害)</li>
<li>self-supervised learning 自监督学习（无监督学习）：常见的语言模型，根据上文学习到embedding，该embedding还能预测下文（设计model，下文不能被偷看，此处self-attention需要加限制，mask掉下文需要预测部分）</li>
<li>token-level<ul>
<li><strong>ELMO</strong> (Embedding from Language Models) (bi-lstm)、<ul>
<li>语言中预测一个单词，需要看它常常跟哪些词汇在一起（上下文）</li>
<li>双向：基于上文预测下文，基于下文预测上文，再结合两部分embedding（按什么比例结合，看任务）</li>
<li>缺点：每个LSTM<strong>只看到了部分的文本</strong>，各自工作</li>
</ul>
</li>
<li><strong>GPT</strong> (Generative Pre-Training)（从上文预测下文，Left-to-Right）不希望fine-tune，直接pretrain解决问题<ul>
<li>Transformer decoder部分</li>
<li>GPT3</li>
<li>in-context learning 纯文本输入，让模型理解文本内容<ul>
<li>few-shot learning： 输入：给出问题描述和少许例子，让模型读题目写答案</li>
<li>one-shot learning： 输入：给出问题描述和1个例子，让模型读题目写答案</li>
<li>zero-shot learning： 输入：给出问题描述，让模型读题目写答案</li>
</ul>
</li>
<li>closed book QA<ul>
<li>直接问问题，模型给出答案（问加法问题，直接给出答案）</li>
</ul>
</li>
</ul>
</li>
<li><strong>BERT</strong> (Bidirectional Encoder Representations from Transformer) (限定文本长度 512)<ul>
<li>Transformer encoder部分</li>
<li>bert可以<strong>随机mask部分词汇</strong>，根据上下文的self-attention去预测mask的词汇，规避了ELMo的缺点（类似CBOW，求和固定的全部上下文，预测mask东西，bert的attention可以自己需要多少看多少）</li>
<li>mask 输入的whole word(整个单词)(bert模型)、phrase-level(短语) &amp; entity-level(实体)(ERNIE模型)、mask 多个token (span bert模型)</li>
<li>“语言模型中，上下文乱序也能学出mask的token”</li>
<li><strong>Transformer-XL</strong> 可以跨文本读取更长的文本</li>
<li><strong>XLNet</strong> (内部使用Transformer-XL)（mask掉的token，不参与预测计算，并且是随机选择上下文）</li>
<li>Reformer, Longformer 解决self-attention计算量的问题</li>
<li>bert缺点：假如必须上文预测下文，则bert效果不太好，但若是不需要按顺序预测，估计bert也ok</li>
</ul>
</li>
<li>seq2seq 的pretrain<ul>
<li>autoencoder+attention，破坏（mask、多个mask、删除、乱序）的输入部分，去预测正确的输入（BART/MASS模型）</li>
<li><strong>BART/MASS</strong>：综合bert和gpt，前面部分使用bert双向attention，后面部分使用单向的attention</li>
<li>UniLM：综合bert、gpt、BART/MASS三个模型</li>
</ul>
</li>
<li>ERNIE (Enhanced Representation through Knowledge Integration)<ul>
<li>为中文设计，mask盖住phrase-level(短语) &amp; entity-level(实体)</li>
<li>加入图谱</li>
</ul>
</li>
<li>Grover (Generating aRticles by Only Viewing mEtadata Records)</li>
<li>BERT &amp; PALs (Projected Attention Layers)</li>
<li>ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately)<ul>
<li>置换token，语法没错，之改变语义</li>
<li>不做embedding，对每个token做yes/no二分类，检查句子所有token是否有问题</li>
<li>先用个small bert的预测一个token，填入原句，再利用model进行判断是否有问题</li>
</ul>
</li>
</ul>
</li>
<li>sentence-level，为整个句子进行embedding<ul>
<li>skip thought (encode上句，decode下句) : 根据上一句生产下一句的embedding，相邻句子，embdding类似</li>
<li>qiuck thought (分别encode上句、下句) : 避开做生成seq（计算量很大），相近句子，embdding越相似</li>
<li>bert中，两个句子学习NSP (next stence prediction)，[CLS]做分类（效果不好，检测是否相关还ok，顺序就不太行）</li>
<li>使用SOP (sentence order prediction) 两句话颠倒（顺序很重要），则要输出错误</li>
<li>结合NSP和SOP会更好</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>How to fine-tune?<ul>
<li>句子分割符号：seq1 [SEP] seq2</li>
<li>句首符号：[CLS] seq<ul>
<li>one class<ul>
<li>[CLS]可以代表整个句子的embedding，可以用[CLS]的embedding做分类</li>
<li>用所有embedding求平均或者RNN综合输出一个embedding做分类</li>
</ul>
</li>
<li>class for each token<ul>
<li>将所有token输入一个分类器做多分类</li>
</ul>
</li>
<li>copy from input<ul>
<li>Extracetion-base QA: 输入Document、Query，输出文本两个下标，代表答案范围</li>
<li>输入[CLS] query [SEP] Document，得到document所有token的输出，分别用两个向量，在token中做dot-product or LSTM再接softmax，选择最高成绩，分别作为起始下标和终止下标</li>
</ul>
</li>
<li>seq2seq<ul>
<li>传统做法为，encoder-decoder + attention，存在decoder中的token没有在encoder见识过（没有pretrain过）</li>
<li>输入seq1 [SEP] seq2，输出根据[SEP]开始，预测seq2第一个的token，最后个token预测结束字符</li>
</ul>
</li>
</ul>
</li>
<li>fine-tune方法<ul>
<li><strong>pretrain作为特征提取，固定不变，再接入下游任务</strong> （更优，pretrain模型很大）</li>
<li>pretrain 和 下游任务一起训练 （pretrain有预训练参数不是随机参数，所以也不会直接过拟合）</li>
<li>折中做法：Adaptor模型，fine-tune时候，pretrain中加入adapter层（self-attention后，前馈神经网络后面），adaptor层与下游任务一起训练，pretrian部分不变</li>
</ul>
</li>
<li>有实验证明 基于pretrain的模型，loss会下降很快，也就是可以快速训练，范化能力更强</li>
</ul>
</li>
</ul>
</li>
<li></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2021/04/14/NLP/" data-id="cknipj2pl000pj0eg02vg2ocv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Interview" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/04/09/Interview/" class="article-date">
  <time datetime="2021-04-09T09:34:54.000Z" itemprop="datePublished">2021-04-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/04/09/Interview/">Interview</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li><p>简历项目</p>
<ul>
<li>自适应图聚类<ul>
<li>GCN细节<ul>
<li>2016年诞生</li>
<li>针对非结构化数据（（欧氏空间）结构化数据：一维的文本or信号、二维的图片）</li>
<li><font color="red">基于拓扑结构与节点属性特征，卷积过程：传播节点信息，汇聚邻居节点信息来更新自身节点。</font>（计算公式上，基于邻接矩阵求得拉普拉斯矩阵，再与特征矩阵做内积，意义在于从谱域傅里叶转换到频域做乘积计算，再逆傅里叶转换回谱域，实现卷积的过程）</li>
<li>CNN的卷积操作属于GCN的一种特殊情况（3x3九宫格中，中心节点汇聚周围8个节点的信息）</li>
<li>本质实在数据中做<strong>低通滤波</strong>的作用，过滤高频噪声信息，提取出低频信息（类似于CNN人脸识别的时候获得人脸五官的基础特征信息，叠加深层之后，获得整个人脸特征）</li>
</ul>
</li>
<li>用什么方法解决了什么问题？结果如何？<ul>
<li>问题：图神经网的浅层、深层会出现过平滑问题、所有节点卷积层是固定的</li>
<li>将RNN中自适应机制转移到GNN中，实现所有节点可以自适应控制自己的卷积层数，有效缓解过平滑问题，学习到更好的embedding，效果在不同数据有3%～6%的提升。</li>
<li>基于聚类两大特性设计损失函数（簇内的距离应当越小，簇间的距离应当越大），也属于自监督学习（无监督学习）</li>
</ul>
</li>
<li>应用场景<ul>
<li>基于拓扑结构和特征信息的聚类操作、推荐系统、知识图谱、蛋白质相互作用网络、社交网络、风控网络</li>
</ul>
</li>
</ul>
</li>
<li>病毒宿主预测任务<ul>
<li>问题：分析病毒基因数据，预测宿主</li>
<li>针对基因学习序列信息，基于宿主构造拓扑结构，实现匹配网络</li>
</ul>
</li>
<li>卷积循环神经网络<ul>
<li>问题：提取过去时序图片信息、预测未来某一时刻图片信息</li>
<li>CNN+LSTM</li>
</ul>
</li>
</ul>
</li>
<li><p>机器学习、深度学习</p>
<ul>
<li><p><font color="red">SVM原理</font></p>
<ul>
<li>提出SVM是为了解决二分类问题；成功分类的直线（平面）有无数个，SVM就要找到最优的结果（即<strong>所有样本距离平面都足够大</strong>）max margin(w, b) s.t. yi (w^T xi + b) &gt; 0<ul>
<li>最优平面：w x+b，参数需要基于样本学习</li>
</ul>
</li>
<li>hard-margin SVM是基于样本属于可分的，但是实际数据是存在噪声，可能导致分不好，甚至不可分<ul>
<li>二次凸优化问题<ul>
<li>符合参数的偏导为0，才能转换对偶问题（max min交换）</li>
<li>针对线性可分数据</li>
</ul>
</li>
</ul>
</li>
<li>soft-margin SVM在hard-margin SVM基础上允许一点点错误</li>
<li><font color="red">kernel函数</font>，是针对完全非线性的数据，<strong>非线性转换到高维空间，转成线性可分问题</strong>，再使用SVM。（高维空间比低维更易线性可分）（深度学习使用多层感知机解决异或问题，可以不转高维）<ul>
<li>kernel 函数还可以解决对偶问题（计算高维空间内积运算），直接得到内及结果，不需要先得到单个函数结果，再计算内积。</li>
</ul>
</li>
</ul>
</li>
<li><p>牛顿法</p>
</li>
<li><p>LSTM</p>
<ul>
<li>Long short-term memory 长短期记忆，可以解决梯度消失和梯度爆炸</li>
<li>对于RNN，多出cell state来记忆之前的信息，变化较慢</li>
<li>忘记阶段。这个阶段主要是对上一个节点传进来的输入进行选择性忘记（<a href="https://zhuanlan.zhihu.com/p/100948638" target="_blank" rel="noopener">忘记不重要的，记住重要的</a>）<ul>
<li>sigmoid层，选择部分忘记</li>
</ul>
</li>
<li>记忆阶段。这个阶段将这个阶段的输入有选择性地进行“记忆”<ul>
<li>sigmoid层，决定什么值需要更新</li>
<li>tanh层，创建一个新的候选值向量，生成候选记忆</li>
</ul>
</li>
<li>输出阶段。这个阶段将决定哪些将会被当成当前状态的输出<ul>
<li>sigmoid层，确定细胞状态的哪部分需要输出</li>
</ul>
</li>
</ul>
</li>
<li><p>DeepWalk</p>
<ul>
<li><p>思想类似word2vec，使用图中节点与节点的共现关系来学习节点的向量表示，<a href="https://leovan.me/cn/2020/04/graph-embedding-and-gnn/" target="_blank" rel="noopener">学习node embedding（在没有feature）</a></p>
</li>
<li><p>网络节点的表示中<strong>节点构成的序列</strong>就是随机游走，网络上不断重复地随机选择游走<strong>路径</strong></p>
</li>
<li><p>从某个特定的端点开始，游走的每一步都从与当前节点相连的边中随机选择一条（固定长度），沿着选定的边移动到下一个顶点，不断重复这个过程（类似NLP，当前token预测下个token）（每一个节点映射成d维向量）</p>
<p>  <img src="https://github.com/soloistben/images/raw/master/interview/deepwalk.jpg" alt="deepwalk 绿色部分即为一条随机游走" style="zoom: 80%;"></p>
</li>
<li><p>借用词向量中使用的skip-gram模型</p>
</li>
<li><p>优点：并行化（并行游走采样）、适应性（适应网络局部的变化）</p>
</li>
</ul>
</li>
<li><p>Spectral-GNN和Spatial-GNN的区别</p>
<ul>
<li>本质一样，GNN是一个热传导模型/信息扩散模型，从不同方式去汇聚信息，更新信息</li>
<li>Spatial-GNN<ul>
<li>直接推广 CNN 的<strong>加权求和思想</strong>，使用不同的领域节点采样方法和不同加权求和方法来更新节点特征</li>
<li>可以多种不同的采样方式，多种不同的加权求和方式</li>
<li>GraphSAGE 和 GAT 等都可以 Inductive learning，扩展到新的节点和新的图，因为这一类方法直接学习的采样过程和加权求和方式（GraphSAGE 还支持 mini-batch 的训练方式）</li>
<li>GraphSAGE：每一层的node的表示都是由上一层生成的，跟本层的其他节点无关<ul>
<li>聚合邻居节点方法：mean、GCN(归一化的拉普拉斯再sum)、LSTM(忽略顺序)、max-pooling</li>
<li>GIN理论证明sum方法较好，比较合理</li>
<li>与GCN比，相对灵活，迁移性强，理论上没差</li>
</ul>
</li>
</ul>
</li>
<li>Spectral-GNN<ul>
<li>从 CNN 的<strong>卷积定理</strong>，f 和 g 的卷积是 f 和 g 傅里叶变换之后乘积的傅里叶逆变换。然后通过拉普拉斯矩阵来实现傅里叶变换和逆傅里叶变换</li>
<li>算是基于图谱理论的Spatial-GNN的特例</li>
<li>优点：捕捉graph的全局信息，从而很好地表示node的特征；理论性强</li>
<li>缺点：<ul>
<li>Transductive，都是单独的图结构，不能迁移到其他图结构（GAT，可以不受图结构影响）</li>
<li>同阶邻居权重一样（GAT是可以不一样，attention）</li>
<li>所有节点一起训练，无法快速学习新的node embedding（GraphSAGE 支持 mini-batch ）</li>
</ul>
</li>
</ul>
</li>
<li>新增加点意味着环境变了，那之前的节点的表示自然也应该有所调整<ul>
<li>Inductive：<strong>对于老节点，可能新增一个节点对其影响微乎其微</strong>，所以可以暂且使用原来的embedding</li>
<li>Transductive：面对新节点，必须更新全部节点</li>
</ul>
</li>
</ul>
</li>
<li><p>有向图GNN</p>
<ul>
<li>GCN不可以使用在有向图，<strong>拉普拉斯需要对称才能正交分解</strong>，GAT可以用在有向图</li>
</ul>
</li>
<li><p>CNN卷积核计算、池化计算</p>
<ul>
<li>图片大小n*n*c，卷积核大小f*f*c、卷积核个数为m个，padding大小p（为了保留边缘信息），步长stride为s</li>
<li>padding后图片为(n+2p)*(n+2p)*c</li>
<li>卷积核后图片三维：<strong>((n+2p-f)/s + 1)*((n+2p-f)/s + 1)*m</strong></li>
<li>使用尺寸大的卷积核，计算量大，多个小尺寸的，达到一样效果，但是计算量更小</li>
<li>池化（缩小模型大小，提高计算速度，提高特征的robust ）计算与卷积一样（一般不加padding）</li>
<li>卷积（padding保持图片大小）+池化（无padding，缩小图片）=卷积层</li>
<li>与全连接层相比，卷积层有两大优势：<ul>
<li>parameter sharing<strong>（卷积核）参数共享</strong>（节省参数，在卷积操作时，卷积计算可以在不同图片区域使用相同的参数，一个过滤器适合一个图片某一块，则也会适合另一块）</li>
<li>sparsity connections<strong>稀疏连接</strong>（输入少，相比全连接而言，不需要输入全部参数，只要满足卷积核大的输入个数），有着两个优势也可以预防过拟合</li>
<li>参数计算：(f*f+1)*c，1为bias，全连接参数=输入输出所有参数的乘积</li>
</ul>
</li>
</ul>
</li>
<li><p>解决过拟合方法</p>
<ul>
<li><p>dropout原理、设置原理</p>
<ul>
<li><p>在训练时，设置dropout使部分神经元暂时隐藏（不起作用），<font color="red"> 减少特征（隐层节点）间的相互作用，缓解过拟合（类似正则化）</font>，梯度下降仅更新未隐藏的神经元。（再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 ）</p>
<p><img src="https://github.com/soloistben/images/raw/master/interview/dropout.png" alt="dropout" style="zoom:80%;"></p>
</li>
<li><p>在过拟合严重处可降低dropout概率，不担心过拟合处可提高dropout概率</p>
</li>
<li>不在输入层使用dropout</li>
<li>一般认为设置为0.5或者0.3（Dropout是一个超参，需要根据具体的网络、具体的应用领域进行尝试）</li>
<li>在测试时不需要</li>
<li>除非出现过拟合状态，否则不用dropout，在计算机视觉常用dropout，在别的领域少用</li>
</ul>
</li>
<li>损失函数加入权重正则化一起训练（正则化是损失函数的惩罚项，对某些参数做一些限制）<ul>
<li><font color="red"> L1, L2的正则化</font><ul>
<li>L1（平均绝对误差，MAE，mean average error）：目标值与预测值的绝对误差值的总和<ul>
<li>鲁棒性、不稳定性、可能有多个解（在非稀疏向量上的计算效率就很低）</li>
<li>符合拉普拉斯分布，是不完全可微的，在图像上会有很多角出现（造成最优值出现在坐标轴上，<strong>因此就会导致某一维的权重为0</strong> ，产生<strong>稀疏权重矩阵</strong>，进而防止过拟合）</li>
<li>L1正则化是指权值向量中各个元素绝对值之和</li>
<li><strong>优点</strong>：输出具有稀疏性，<strong>即产生一个稀疏模型，进而可以用于特征选择</strong>（会趋向于产生少量的特征，而其他的特征都是0）；一定程度上，L1也可以防止过拟合</li>
<li><strong>缺点</strong>：但在非稀疏情况下计算效率低，存在多个解</li>
<li><font color="red">如果特征符合稀疏性，说明特征矩阵很多元素为0，只有少数元素是非零的矩阵，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，或者贡献微小（因为它们前面的系数是0或者是很小的值，即使去掉对模型也没有什么影响）</font>，此时就可以只关注系数是非零值的特征。</li>
</ul>
</li>
<li>L2（均方误差，MSE，mean squared error）：目标值与预测值的差值均方和<ul>
<li>不是很鲁棒性、稳定、一个解（计算方便）</li>
<li>高斯分布，是完全可微的，图像上的棱角比较圆滑（参数<strong>不断趋向于0</strong>）</li>
<li><font color="red">如果误差大于1，则误差会放大更多（比L1更大），因此模型会对样本更加敏感</font>（若有一个异常样本，模型需要调整or牺牲很多正常样本，来适应单个异常值，正常的样本的误差比这单个的异常值的误差小）</li>
<li>L2正则化是指权值向量中各个元素的平方和然后再求平方根</li>
<li><strong>优点</strong>：计算效率高（因为存在解析解）；可以防止模型过拟合；选择更多的特征，这些特征都会接近于0</li>
<li><strong>缺点</strong>：非稀疏输出；无特征选择</li>
</ul>
</li>
</ul>
</li>
<li>L1与L2的区别只在于，L2是权重的平方和，而L1就是权重的和</li>
</ul>
</li>
<li>权重过大会引起梯度爆炸</li>
<li>降低模型复杂度、减轻过拟合</li>
<li>数据增强</li>
<li>提早结束，在出现过拟合之前</li>
</ul>
</li>
<li><p>bert预训练与word2vector比较</p>
<ul>
<li>BERT使用Transformer中encoder部分的self-attention、Mask Language Model、Next Sentence Prediction<ul>
<li>BERT的本质上是通过在海量的语料的基础上运行自监督学习方法为单词学习一个好的特征表示（自监督学习属于无监督学习）<ul>
<li><font color="red">Mask Language Model</font>：在训练时在输入中随机mask 15%单词，然后根据上下文预测单词（完型填空）（80%直接mask、10%更换任意单词、10%保留原单词）（若100%mask掉，有可能在微调模型时候，没有见过某些单词）</li>
<li>Next Sentence Prediction：判断第二句话是否第一句话的下文，50%的IsNext和50%的NotNext（选择题（多分类）、判断题（二分类）、简答题（回归））</li>
</ul>
</li>
</ul>
</li>
<li>word2vector<ul>
<li>Skip-gram：如果是用一个词语作为输入，来预测它周围的上下文<ul>
<li>CBOW：如果是拿一个词语的上下文作为输入，来预测这个词语本身</li>
</ul>
</li>
<li>one-hot encode输入单词，输入一个神经网络（隐含层未使用激活函数，线性的），得到的embedding则是整个word2vector模型，同时加入整个模型的训练（质上是一种<font color="red">降维操作</font>，词袋数量很大时候，onehot维度很大，则用神经网络降维到固定的维度）<ul>
<li>训练trick: hierarchical softmax (把 N 分类问题变成 log(N)次二分类) 和 negative sampling(预测总体类别的一个子集)</li>
<li>word2vector 本质上是一个语言模型，它的输出节点数是 V 个，对应了 V 个词语，本质上是一个多分类问题，但实际当中，词语的个数非常非常多，会给计算造成很大困难，所以需要用技巧来加速训练</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>多分类问题</p>
<ul>
<li>拆成多个二分类<ul>
<li>例如三分类拆成一个为一类，两个看成另一类，但会出现样本不均衡问题</li>
<li>四分类拆成一对一对，分别将两个看成一类</li>
</ul>
</li>
</ul>
</li>
<li><p>激活函数</p>
<ul>
<li>sigmoid、tanh会引起梯度消失，relu不会</li>
<li>relu在x=0处不可导，但实际情况很少会出现靠近0的数，则可以忽略</li>
<li>线性函数作为激活函数一般是在输出时（全连接层）</li>
<li>实际上大多数现象呈现关系都是<strong>正相关</strong>关系，并非线性关系，因此用非线性函数作为激活函数是更适合表达正相关关</li>
</ul>
</li>
<li><p>模型调参（如何让模型更加鲁棒性）</p>
<ul>
<li>数据层面上<ul>
<li>training时候保证数据是打乱顺序，防止学习到输入的顺序信息，会使模型更加鲁棒性</li>
<li>数据增强（增加数据多样性）</li>
<li>数据采用，尽可能数据平衡，训练集验证集测试集分布要一致</li>
<li>数据不平衡的时候，在训练期间应用类别加权操作。<a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html" target="_blank" rel="noopener">给稀少的类更多的权重，给主要类更少的权重；sklearn计算类权重</a>，<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis" target="_blank" rel="noopener">或者尝试使用过采样和欠采样技术重新采样你的训练集</a></li>
</ul>
</li>
<li>模型过拟合层面<ul>
<li>针对模型做一些正则化操作（L1、L2、Dropout）</li>
<li>早停机制</li>
</ul>
</li>
<li>训练层面<ul>
<li>选择正确的优化器（关心快速收敛，使用自适应优化器，如Adam，但它可能会陷入局部最小；SGD+momentum可以实现找到全局最小值，但它依赖于鲁棒初始化，而且可能比其他自适应优化器需要更长的时间来收敛）<ul>
<li>Adam和SGD，优化方法<ul>
<li>优化算法的功能，是通过改善训练方式，来最小化(或最大化)损失函数E(x)<ul>
<li><strong>SGD</strong>梯度下降主要用于在神经网络模型中进行权重更新，即在一个方向上更新和调整模型的参数，来最小化损失函数</li>
<li>momentum通过优化相关方向的训练和弱化无关方向的振荡，来加速SGD训练，使网络能更优和更稳定的收敛；减少振荡过程（通常设定为0.9）</li>
<li>当其梯度指向实际移动方向时，动量项γ增大；当梯度与实际移动方向相反时，γ减小。这种方式意味着动量项只对相关样本进行参数更新，减少了不必要的参数更新，从而得到更快且稳定的收敛，也减少了振荡过程。</li>
</ul>
</li>
<li><strong>Adam</strong> （Adaptive Moment Estimation）<ul>
<li>计算每个参数的自适应学习率</li>
<li>在稀疏数据集使用，效果好</li>
</ul>
</li>
<li>在数据统计特性明显，分布好计算（估计）的时候，容易调整SGD的参数，使得SGD收敛好（设置好参数，<font color="red">可以达到全局最优</font>）</li>
<li>在数据统计特性不好，变化大，误差曲面复杂的时候，优先使用傻瓜算法Adam（简化了调参，但默认参数，<font color="red">可能会导致不收敛、局部最优</font>）</li>
</ul>
</li>
</ul>
</li>
<li>调整学习率（0.1，0.001，0.000001，以10为阶数进行尝试），微调：0.001；完整训练：&gt;=0.001。使用衰减学习率。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>python</p>
<ul>
<li><p>深拷贝原理</p>
<ul>
<li>直接赋值：其实就是对象的引用（别名）</li>
<li>浅拷贝(copy)：拷贝父对象，不会拷贝对象的内部的子对象</li>
<li><p>深拷贝(deepcopy)： copy 模块的 deepcopy 方法，完全拷贝了父对象及其子对象</p>
<p><img src="https://github.com/soloistben/images/raw/master/interview/deepcopy.png" alt="deepcopy" style="zoom: 80%;"></p>
</li>
</ul>
</li>
<li><p>垃圾回收机制</p>
<ul>
<li>主要通过<strong>引用计数（Reference Counting）</strong>进行垃圾回收<ul>
<li>每一个对象的核心就是一个结构体（内部有一个引用计数器）</li>
<li>引用计数+1：创建、引用、作为参数传入到函数、作为元素存储在容器（list、set等）</li>
<li>引用计数-1： del销毁对象、对象被赋予新对象、对象离开作用域、容器被销毁or容器删除该元素</li>
<li>引用计数法有其明显的优点，如高效、实现逻辑简单、具备实时性，<font color="red">一旦一个对象的引用计数归零，内存就直接释放了 </font> （缺点是需要单独分配空间来维护引用计数、当释放一个较大的对象时需要较长时间、循环引用是该机制必然存在的，需要算法对其补充）</li>
<li>只有容器对象才会产生<strong>循环引用</strong>的情况，比如列表、字典、用户自定义类的对象、元组等<ul>
<li>“标记-清除”(Mark and Sweep)算法（双端链表，一个链表存放着需要被扫描的容器对象，另一个链表存放着临时不可达对象）：<ul>
<li>标记阶段，遍历所有的对象，是否还有<strong>对象引用它</strong>，那么就标记该对象为可达</li>
<li>清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。</li>
<li>垃圾回收的阶段，会暂停整个应用程序，等待标记清除结束后才会恢复应用程序的运行</li>
</ul>
</li>
<li>分代回收(Generational Collection)<ul>
<li>上面算法需要暂停应用，分代回收以空间换时间，减少暂停时间</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>多线程<ul>
<li><font color="red">多线程类似于同时执行多个不同程序</font></li>
<li>优点<ul>
<li>占据长时间的程序中的任务放到后台去处理</li>
<li>程序的运行速度可能加快</li>
<li>在一些等待的任务使用多线程，释放一些珍贵的资源占用</li>
</ul>
</li>
<li>线程在执行过程中与进程还是有区别的。每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。</li>
<li>每个线程都有他自己的一组CPU寄存器，称为线程的上下文，该上下文反映了线程上次运行该线程的CPU寄存器的状态</li>
<li>指令指针和堆栈指针寄存器是线程上下文中两个最重要的寄存器，线程总是在进程得到上下文中运行的，这些地址都用于标志拥有线程的进程地址空间中的内存。<ul>
<li>线程可以被抢占（中断）</li>
<li>在其他线程正在运行时，线程可以暂时搁置（也称为睡眠） — 这就是线程的退让</li>
</ul>
</li>
<li>线程可以分为:<ul>
<li><strong>内核线程：</strong>由操作系统内核创建和撤销</li>
<li><strong>用户线程：</strong>不需要内核支持而在用户程序中实现的线程</li>
</ul>
</li>
<li><a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017627212385376" target="_blank" rel="noopener">进程与线程</a><ul>
<li>每个进程至少要干一件事，一个进程至少有一个线程（线程是最小的执行单元），复杂程序有多个线程（比如Word，它可以多个线程同时进行打字、拼写检查、打印等事情）</li>
<li>操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，看起来就像同时执行一样</li>
<li>多任务三种模式：多进程、多线程、多进程+多线程（复杂、少用）</li>
<li>涉及到同步、数据共享的问题</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>基础知识点（数据结构）</p>
<ul>
<li>数组、链表<ul>
<li>数组元素存储地址连续（若频繁访问某个下标的元素，选择数组方式，时间复杂度O(1)）</li>
<li>链表元素存储地址不连续（若频繁访问某个下标的元素，需要从头访问，时间复杂度O(n)）</li>
</ul>
</li>
<li><font color="red">快速排序原理</font><ul>
<li>选择第一个元素的值做准基数</li>
<li>在右边找到较小的值放到左边、在左边找到较大值放到右边，达到左侧元素小于准基数，右侧大于准基数</li>
<li>每次根据选择后点的位置，划分成两部分，再分别进行上诉操作</li>
<li>达到小到大的排序</li>
</ul>
</li>
</ul>
</li>
<li><p>大数据（spark，hadoop）</p>
</li>
</ol>
<p>code</p>
<ul>
<li><p>quick_sort</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(arr, low, high)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(arr, low, high)</span>:</span></span><br><span class="line">        p = arr[low]	<span class="comment"># 设定当前low位置为基准</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> low&lt;high:</span><br><span class="line">            <span class="keyword">while</span> low&lt;high <span class="keyword">and</span> arr[high]&gt;=p:	<span class="comment"># 在右边找比基准小的数</span></span><br><span class="line">                high -= <span class="number">1</span></span><br><span class="line">            arr[low] = arr[high]	<span class="comment"># 放置左边</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">while</span> low&lt;high <span class="keyword">and</span> arr[low]&lt;=p:		<span class="comment"># 在左边找到比基准大的数 </span></span><br><span class="line">                low += <span class="number">1</span></span><br><span class="line">            arr[high] = arr[low]	<span class="comment"># 放置右边</span></span><br><span class="line">       	</span><br><span class="line">        arr[low] = p	<span class="comment"># 放置基准</span></span><br><span class="line">        <span class="keyword">return</span> low 		<span class="comment"># 返回基准下标</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> low&lt;high:</span><br><span class="line">        mid = partition(arr, low, high)	<span class="comment"># 找到一个准基数下标</span></span><br><span class="line">        quick_sort(arr, low, mid<span class="number">-1</span>)		<span class="comment"># 左边是小于准基数的部分，进行快排</span></span><br><span class="line">        quick_sort(arr, mid, high)		<span class="comment"># 右边是大于准基数的部分，进行快排</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>DFS (Depth First Search)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">neighbor_dict = &#123;node1:[neighbor1, ...], ...&#125;	<span class="comment"># 邻居集合，数据处理成邻接表形式</span></span><br><span class="line">node_list = [node1, node2, ...]	<span class="comment"># 所有节点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归</span></span><br><span class="line">visited = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DFS_Traverse</span><span class="params">(node_list)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> node_list:	<span class="comment"># 这层遍历防止非连通子图</span></span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">            DFS(G, node)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DFS</span><span class="params">(node)</span>:</span></span><br><span class="line">    <span class="string">'''针对node做操作'''</span></span><br><span class="line">    visited.append(node)</span><br><span class="line">    <span class="comment"># 遍历邻居</span></span><br><span class="line">    <span class="keyword">for</span> neighbor <span class="keyword">in</span> neighbor_dict[node]:	</span><br><span class="line">        <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">            DFS(neighbor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 非递归(使用栈)(直接指定某个起始节点，并非完整图的一个DFS)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DFS_Traverse</span><span class="params">(node, neighbor_dict)</span>:</span></span><br><span class="line">    stack = []		<span class="comment"># list模仿栈</span></span><br><span class="line">	visited = []</span><br><span class="line">    </span><br><span class="line">    stack.append(node)	<span class="comment"># 入栈起始节点</span></span><br><span class="line">  	visited.append(node)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(stack)&gt;<span class="number">0</span>:</span><br><span class="line">        node = stack.pop()	<span class="comment"># 弹出栈顶的元素</span></span><br><span class="line">        <span class="string">'''针对node做操作'''</span></span><br><span class="line">        <span class="comment"># 遍历邻居</span></span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> neighbor_dict[node]:	</span><br><span class="line">            <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                stack.append(neighbor)</span><br><span class="line">                visited.append(neighbor)</span><br></pre></td></tr></table></figure>
</li>
<li><p>BFS (Breadth First Search)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">neighbor_dict = &#123;node1:[neighbor1, ...], ...&#125;	<span class="comment"># 邻居集合，数据处理成邻接表形式</span></span><br><span class="line">node_list = [node1, node2, ...]	<span class="comment"># 所有节点</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''非递归'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BFS_Traverse</span><span class="params">(node_list)</span>:</span></span><br><span class="line">    queue = []</span><br><span class="line">	visited = []</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> node_list:	<span class="comment"># 这层遍历防止非连通子图</span></span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">            <span class="string">'''针对node做操作'''</span></span><br><span class="line">            queue.append(node)	<span class="comment"># 入队起始节点</span></span><br><span class="line">            visited.append(node)</span><br><span class="line">            <span class="keyword">while</span> len(queue):</span><br><span class="line">                start_node = queue.pop(<span class="number">0</span>)	<span class="comment"># 弹出队头的起始节点，找邻居</span></span><br><span class="line">                <span class="comment"># 遍历邻居</span></span><br><span class="line">                <span class="keyword">for</span> neighbor <span class="keyword">in</span> neighbor_dict[start_node]:	</span><br><span class="line">                    <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                        <span class="string">'''针对node做操作'''</span></span><br><span class="line">                        queue.append(neighbor)	<span class="comment"># 入队邻居节点</span></span><br><span class="line">            			visited.append(neighbor)</span><br><span class="line">                        </span><br><span class="line"><span class="string">'''BFS 求无权图某节点的最短路径'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BFS_Min_Distance</span><span class="params">(node, node_list)</span>:</span></span><br><span class="line">    queue = []</span><br><span class="line">    visited = []</span><br><span class="line">    d = &#123;node_:<span class="number">0</span> <span class="keyword">for</span> node_ <span class="keyword">in</span> node_list&#125;	<span class="comment"># 初始化为0，n个的距离数组</span></span><br><span class="line">    </span><br><span class="line">    queue.append(node)	<span class="comment"># 入队起始节点</span></span><br><span class="line">    visited.append(node)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(queue):</span><br><span class="line">        start_node = queue.pop(<span class="number">0</span>)	<span class="comment"># 弹出队头的起始节点，找邻居</span></span><br><span class="line">        <span class="comment"># 遍历邻居</span></span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> neighbor_dict[start_node]:	</span><br><span class="line">            <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                <span class="string">'''针对node做操作'''</span></span><br><span class="line">                d[neighbor] = d[start_node] + <span class="number">1</span> </span><br><span class="line">                queue.append(neighbor)	<span class="comment"># 入队邻居节点</span></span><br><span class="line">                visited.append(neighbor)</span><br></pre></td></tr></table></figure>
</li>
<li><p>LCS (Longest Common Subsequence)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"> <span class="string">'''最长公共子序列，（递归）暴力破解版，自顶向下'''</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">LCS_rc</span><span class="params">(text1, text2)</span>:</span></span><br><span class="line">    <span class="comment"># 最基本，若其中一个为空序列，则没有公共部分</span></span><br><span class="line">    <span class="keyword">if</span> len(text1)==<span class="number">0</span> <span class="keyword">or</span> len(text2)==<span class="number">0</span>:  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> text1[<span class="number">-1</span>] == text2[<span class="number">-1</span>]:</span><br><span class="line">        <span class="keyword">return</span> LCS_rc(text1[:<span class="number">-1</span>], text2[:<span class="number">-1</span>]) + <span class="number">1</span>   <span class="comment"># 找到一个就加1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 找不到就各缩短一边来再做比较</span></span><br><span class="line">        <span class="keyword">return</span> max(LCS_rc(text1[:<span class="number">-1</span>], text2), LCS_rc(text1, text2[:<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="string">'''自底向上'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">LCS</span><span class="params">(text1, text2)</span>:</span></span><br><span class="line">    <span class="comment"># 创建二维表格，多创建一行，0行0列作为全零，不变，用于后续计算</span></span><br><span class="line">    <span class="comment"># 利用循环生成list，防止出现引用问题</span></span><br><span class="line">    <span class="comment"># text1 作为纵向，text2作为横向</span></span><br><span class="line">    dp = [[<span class="number">0</span>]*(len(text2)+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(text1)+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(text1)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, len(text2)+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> text1[i<span class="number">-1</span>] == text2[j<span class="number">-1</span>]:</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j<span class="number">-1</span>]+<span class="number">1</span> <span class="comment"># 找到一个公共元素</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = max(dp[i<span class="number">-1</span>][j], dp[i][j<span class="number">-1</span>])  <span class="comment"># 取相邻近的较大元素</span></span><br><span class="line">    <span class="keyword">return</span> dp[<span class="number">-1</span>][<span class="number">-1</span>]   <span class="comment"># 最后一个元素即公共子序列长度</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>0/1背包（动态规划）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">3</span>   <span class="comment"># 每件物品只能装一次</span></span><br><span class="line">W = <span class="number">4</span></span><br><span class="line">wt = [<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]  <span class="comment"># 每个物品的重量</span></span><br><span class="line">val = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>] <span class="comment"># 每个物品的价值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dp[i][w]: 对前i个物品，当前背包容量为w，最大价值则为dp[i][w]</span></span><br><span class="line"><span class="comment"># dp[3][5]=6: 对前3个物品，当前背包容量为5时，可以装下最大价值为6</span></span><br><span class="line">dp = [[<span class="number">0</span>]*(W+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(N+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, N+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> range(<span class="number">1</span>, W+<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 当前容量w</span></span><br><span class="line">        <span class="comment"># 装第i件物品：dp[i-1][w-wt[i-1]]+wt[i-1] (w-wt = 剩余背包容量)</span></span><br><span class="line">        <span class="comment"># 不装第i件物品：dp[i-1][w]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> w-wt[i<span class="number">-1</span>] &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 装不下了</span></span><br><span class="line">            dp[i][w] = dp[i<span class="number">-1</span>][w]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 能装下情况，选价值大的</span></span><br><span class="line">            dp[i][w] = max(dp[i<span class="number">-1</span>][w-wt[i<span class="number">-1</span>]]+val[i<span class="number">-1</span>], dp[i<span class="number">-1</span>][w])</span><br></pre></td></tr></table></figure>
</li>
<li></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2021/04/09/Interview/" data-id="cknipj2q50016j0egqbc6anm6" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-C-plus-note" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/17/C-plus-note/" class="article-date">
  <time datetime="2020-11-17T08:15:24.000Z" itemprop="datePublished">2020-11-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/11/17/C-plus-note/">C_plus_note</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="One-Definition-of-Class-without-pointer"><a href="#One-Definition-of-Class-without-pointer" class="headerlink" title="One. Definition of Class (without pointer)"></a>One. Definition of Class (without pointer)</h4><ul>
<li><p>防止重复引用头文件（e.g. complex.h 对应 __COMPLEX__）（guard 防卫式声明）</p>
</li>
<li><p>public（定义提供外部调用函数），private （<font color="red"><strong>数据放入private</strong></font>，仅限类内用）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __COMPLEX__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __COMPLEX__</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">complex</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Constructor Function 构造函数</p>
<ul>
<li>构造函数与类名称一样</li>
<li>Overloading 重载（一个类可以重载多个构造函数，下面特例不允许）</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __COMPLEX__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __COMPLEX__</span></span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">complex</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// constructor function </span></span><br><span class="line">    <span class="comment">// (default argument 默认实参，构造函数不需要写返回类型，默认为类)</span></span><br><span class="line">    <span class="keyword">complex</span>(<span class="keyword">double</span> r=<span class="number">0</span>, <span class="keyword">double</span> i=<span class="number">0</span>)   </span><br><span class="line">        : re(r), im(i)      <span class="comment">// initialization list 初始化列表（仅构造函数有）</span></span><br><span class="line">    &#123;...&#125;               	<span class="comment">// r, i 也可以在函数体内是assignments赋值</span></span><br><span class="line">    						<span class="comment">// （但是比初始化列表慢一点）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">complex</span>() 				<span class="comment">// 与上面构造函数冲突，不允许这么设置</span></span><br><span class="line">        : re(<span class="number">0</span>), im(<span class="number">0</span>)</span><br><span class="line">    &#123;...&#125; </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">real</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> re;&#125; <span class="comment">// 不会改变数据内容的函数，必须加const</span></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">imag</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> im;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 数据放入private，仅限类内用</span></span><br><span class="line">    <span class="keyword">double</span> re, im;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>Destructor Function 析构函数（不带指针的类，一般不用写析构函数）</li>
<li>Initialization list 初始化列表（仅构造函数有），<font color="red"><strong>优先考虑使用初始化列表</strong></font></li>
<li><p>构造函数一般写在public，也可以写在private中，但仅限类内调用，外部可用singleton调用，但只能调用一个 </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">static</span> A&amp; <span class="title">getInstance</span><span class="params">()</span></span>;	<span class="comment">// 单例模式</span></span><br><span class="line">    setup() &#123;...&#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    A();</span><br><span class="line">    A(<span class="keyword">const</span> A&amp; rhs);</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">A&amp; A::getInstance()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">static</span> A a;	<span class="comment">// 只有当调用时，才会创建该对象</span></span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 调用</span></span><br><span class="line">A::getInstance().setup();</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>Template 模板</p>
<ul>
<li><p>当未最终确定数据变量的类型时，或者需要多种数据类型，可以<strong>使用Template</strong></p>
</li>
<li><p>当设置多种类型，则当前就有上面类的定义，这是模板带来的代码膨胀（这不是缺点，是必须要两套代码）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __COMPLEX__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __COMPLEX__</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">complex</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// constructor function </span></span><br><span class="line">    <span class="keyword">complex</span>(T r=<span class="number">0</span>, T i=<span class="number">0</span>)   </span><br><span class="line">        : re(r), im(i)</span><br><span class="line">    &#123;...&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">T <span class="title">real</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> re;&#125; <span class="comment">// 不会改变数据内容的函数，必须加const</span></span><br><span class="line">    <span class="function">T <span class="title">imag</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> im;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 数据放入private，仅限类内用</span></span><br><span class="line">    T re, im;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">--------------------------------</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"complex.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">complex</span>&lt;<span class="keyword">double</span>&gt; c1(<span class="number">2.0</span>, <span class="number">1.0</span>);   <span class="comment">// &lt;double&gt; 确定变量类型</span></span><br><span class="line">	<span class="keyword">complex</span>&lt;<span class="keyword">int</span>&gt; c1(<span class="number">2</span>, <span class="number">1</span>);   </span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;c1.real();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>function template 函数模板</p>
<ul>
<li><p>当函数内容一样时，仅传入对象类型不一样，即可使用函数模板</p>
</li>
<li><p>编译器会对function template进行引数推导(argument deduction)（自动检测是什么类型） </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">T</span>&amp; <span class="title">min</span> (<span class="title">const</span> <span class="title">T</span>&amp; <span class="title">a</span>, <span class="title">const</span> <span class="title">T</span>&amp; <span class="title">b</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">return</span> b&lt;a ? b:a;	<span class="comment">// 即使是自定义的类，操作符 &lt; 重载就可以</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>namespace 命名空间（防止命名冲突）</p>
<ul>
<li>directive: “using namespace std;”    写demo时常用</li>
<li>declaration: “using std::cout;”  只声明了一个</li>
</ul>
</li>
<li><p>Inline Function 内联函数</p>
<ul>
<li>在类内定义的函数，且不是复杂函数，都可以编译为inline函数</li>
<li>在类外定义的函数，需要在<font color="red">成员函数前设定特有字符 <strong>inline</strong></font></li>
<li>优点是执行得快</li>
<li>是否变成inline，由编译器决定（创建权在程序员手上，决定权在编译器上）</li>
</ul>
</li>
<li><p>pass Value &amp; pass Reference 传递参数：传值与传引用</p>
<ul>
<li>直接pass value会因为值大小影响函数速度</li>
<li>引用本质也是指针，指针4个字节，速度快</li>
<li><font color="red">**提前考虑是否需要const**</font></li>
<li><p><font color="red"><strong>建议所有参数均传引用，return也尽量返回引用</strong></font>（在变量生命周期外（局部变量）返回引用是错误的，其余情况都可以返回引用）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __COMPLEX__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __COMPLEX__</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">complex</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// constructor function </span></span><br><span class="line">    <span class="keyword">complex</span>(<span class="keyword">double</span> r=<span class="number">0</span>, <span class="keyword">double</span> i=<span class="number">0</span>)   </span><br><span class="line">        : re(r), im(i)</span><br><span class="line">    &#123;...&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// inline function，在类内定义的函数，且不是复杂函数</span></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">real</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> re;&#125; <span class="comment">// 不会改变数据内容的函数，必须加const</span></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">imag</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> im;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">complex</span>&amp; <span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="keyword">complex</span>&amp;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">double</span> re, im;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参数1会被改动，参数2不会被改动（ths是已创建变量，可以当成引用返回）</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span>&amp; __doapl(<span class="keyword">complex</span>* ths, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; r)</span><br><span class="line">&#123;</span><br><span class="line">    ths-&gt;re += r.re;</span><br><span class="line">    ths-&gt;im += r.im;</span><br><span class="line">    <span class="keyword">return</span> *ths;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// inline function</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span>&amp; <span class="keyword">complex</span>::<span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; r)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> __doapl(<span class="keyword">this</span>, r);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>Friend Function 友元函数</p>
<ul>
<li><p>可以直接访问private数据，比函数读取private数据更快（用来做特例，破坏类的整体封装性）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __COMPLEX__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __COMPLEX__</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">complex</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// constructor function </span></span><br><span class="line">    <span class="keyword">complex</span>(<span class="keyword">double</span> r=<span class="number">0</span>, <span class="keyword">double</span> i=<span class="number">0</span>)   </span><br><span class="line">        : re(r), im(i)</span><br><span class="line">    &#123;...&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// inline function，在类内定义的函数，且不是复杂函数</span></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">real</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> re;&#125; <span class="comment">// 不会改变数据内容的函数，必须加const</span></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">imag</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> im;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">complex</span>&amp; <span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="keyword">complex</span>&amp;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">double</span> re, im;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// friend function</span></span><br><span class="line">    <span class="keyword">friend</span> <span class="keyword">complex</span>&amp; __doapl (<span class="keyword">complex</span>*, <span class="keyword">const</span> <span class="keyword">complex</span>&amp;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参数1会被改动，参数2不会被改动（ths是已创建变量，可以当成引用返回）</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span>&amp; __doapl(<span class="keyword">complex</span>* ths, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; r)</span><br><span class="line">&#123;</span><br><span class="line">    ths-&gt;re += r.re;	<span class="comment">// 直接读取private变量</span></span><br><span class="line">    ths-&gt;im += r.im;</span><br><span class="line">    <span class="keyword">return</span> *ths;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// inline function</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span>&amp; <span class="keyword">complex</span>::<span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; r)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// this可以隐藏，不可以写</span></span><br><span class="line">    <span class="comment">// this是默认存在，不是临时变量</span></span><br><span class="line">    <span class="keyword">return</span> __doapl(<span class="keyword">this</span>, r);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>相同class的各个object互为friend</strong>，可以直接获取private数据</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __COMPLEX__</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> __COMPLEX__</span></span><br><span class="line">  </span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">complex</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">      <span class="comment">// constructor function </span></span><br><span class="line">      <span class="keyword">complex</span>(<span class="keyword">double</span> r=<span class="number">0</span>, <span class="keyword">double</span> i=<span class="number">0</span>)   </span><br><span class="line">          : re(r), im(i)</span><br><span class="line">      &#123;...&#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// inline function</span></span><br><span class="line">      <span class="function"><span class="keyword">double</span> <span class="title">real</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> re;&#125;</span><br><span class="line">      <span class="function"><span class="keyword">double</span> <span class="title">imag</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> im;&#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">complex</span>&amp; <span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="keyword">complex</span>&amp;);</span><br><span class="line">  </span><br><span class="line">      <span class="function"><span class="keyword">double</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> <span class="keyword">complex</span>&amp; param)</span></span></span><br><span class="line"><span class="function">      </span>&#123; </span><br><span class="line">          <span class="keyword">return</span> param.re+param.im; <span class="comment">// 直接读取private变量</span></span><br><span class="line">      &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">      <span class="keyword">double</span> re, im;</span><br><span class="line">  &#125;;</span><br><span class="line">  </span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>operator overloading 操作符重载</p>
<ul>
<li>其实跟定义函数一样，只是操作符更直观</li>
<li>编译器会去寻找相关的operator的被重写的函数（不管用什么方法，只能写一个，<strong>编译器只选择其中一个使用，没有优先级</strong>）</li>
<li><p>两种方法：</p>
<ul>
<li><p>成员函数（类内），默认有this</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">// 全局函数</span></span><br><span class="line">  <span class="comment">// 参数1会被改动，参数2不会被改动</span></span><br><span class="line">  <span class="keyword">inline</span> <span class="keyword">complex</span>&amp; __doapl(<span class="keyword">complex</span>* ths, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; r) <span class="comment">// const complex&amp; r （可以用complex，传值，但会慢）</span></span><br><span class="line">  &#123;</span><br><span class="line">      ths-&gt;re += r.re;</span><br><span class="line">      ths-&gt;im += r.im;</span><br><span class="line">      <span class="keyword">return</span> *ths;    <span class="comment">// 传递者(*ths)无需知道接收者(complex&amp;)是以reference形式接收</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 类的成员函数</span></span><br><span class="line">  <span class="keyword">inline</span> <span class="keyword">complex</span>&amp; <span class="keyword">complex</span>::<span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; r)	<span class="comment">// 默认有this，但不能写出来</span></span><br><span class="line">  &#123;</span><br><span class="line">      <span class="keyword">return</span> __doapl(<span class="keyword">this</span>, r);    <span class="comment">// 返回类型必须是引用complex&amp;（防止c3+=c2+=c1; 连续赋值情况）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>非成员函数（类外），无this；写在类外，例如加法有多个情况，全部写在类内是有局限性</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将加法所有情况，都写出来</span></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span> <span class="keyword">operator</span> + (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; x, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; y)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// temp object 临时变量（函数执行完就销毁）</span></span><br><span class="line">    <span class="comment">// 不能当成reference返回</span></span><br><span class="line">    <span class="comment">// 要返回value，才能保存生成的临时变量（局部变量）</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">complex</span>(real(x)+real(y), imag(x)+imag(y));   </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span> <span class="keyword">operator</span> + (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; x, <span class="keyword">double</span> y)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">complex</span>(real(x)+y, imag(x));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span> <span class="keyword">operator</span> + (<span class="keyword">double</span> x, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; y)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">complex</span>(x+real(y), imag(y));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span> <span class="keyword">operator</span> + (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; x)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">complex</span> <span class="keyword">operator</span> - (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; x)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">complex</span>(-real(x), -imag(x));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">bool</span> <span class="keyword">operator</span> == (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; x, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; y)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> real(x)==real(y) &amp;&amp; imag(x)==imag(y);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">bool</span> <span class="keyword">operator</span> == (<span class="keyword">const</span> <span class="keyword">complex</span>&amp; x, <span class="keyword">double</span> y)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> real(x)==y &amp;&amp; imag(x)==<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="keyword">bool</span> <span class="keyword">operator</span> == (<span class="keyword">double</span> x, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; y)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> real(y)==x &amp;&amp; imag(y)==<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">complex</span> <span class="title">conj</span><span class="params">(<span class="keyword">const</span> <span class="keyword">complex</span>&amp; x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">complex</span>(real(x), -imag(x)); <span class="comment">// 共轭复数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="comment">// '&lt;&lt;' 该操作符只能写成全局函数（非成员函数）</span></span><br><span class="line"><span class="comment">// os 用于显示，一直在其内容变化，不能写成const </span></span><br><span class="line">ostream&amp; <span class="keyword">operator</span> &lt;&lt; (ostream&amp; os, <span class="keyword">const</span> <span class="keyword">complex</span>&amp; x)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> os &lt;&lt; <span class="string">'('</span> &lt;&lt; real(x) &lt;&lt; <span class="string">','</span> &lt;&lt; imag(x) &lt;&lt; <span class="string">')'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Two-Definition-of-Class-with-pointer"><a href="#Two-Definition-of-Class-with-pointer" class="headerlink" title="Two. Definition of Class (with pointer)"></a>Two. Definition of Class (with pointer)</h4><ul>
<li><p>当定义类中含有指针，则必须有<font color="red">“拷贝构造”、“拷贝赋值”、“析构函数”</font></p>
<ul>
<li>拷贝构造、拷贝赋值属于深拷贝（深拷贝，即开辟新内存，存储为新数据，与原本数据仅值相同）</li>
<li>若不实现深拷贝，系统默认是浅拷贝，即两个指针指向同一内存</li>
<li><p>析构函数则在对象离开作用域（对象定义的花括号内）后，在析构函数释放数据内存，再销毁对象</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __MY_STRING__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __MY_STRING__</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;ostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">String</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 构造函数</span></span><br><span class="line">    String(<span class="keyword">const</span> <span class="keyword">char</span>* cstr=<span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*带指针的类，必须要有 拷贝构造、拷贝赋值、析构函数*/</span></span><br><span class="line">    <span class="comment">// 拷贝构造（深拷贝，即开辟新内存，存储为新数据，与原本数据仅值相同）</span></span><br><span class="line">    <span class="comment">//（如果不重写，系统默认是浅拷贝，即两个指针指向同一内存）</span></span><br><span class="line">    String(<span class="keyword">const</span> String&amp; str);  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拷贝赋值（深拷贝）</span></span><br><span class="line">    String&amp; <span class="keyword">operator</span> = (<span class="keyword">const</span> String&amp; str);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 析构函数（带有指针的类，需要在对象离开作用域（对象定义的花括号）后，在系够函数释放数据内存）</span></span><br><span class="line">    ~String();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">char</span>* <span class="title">get_data</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;<span class="keyword">return</span> m_data;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 指针 动态分配</span></span><br><span class="line">    <span class="comment">// 数组 固定分配</span></span><br><span class="line">    <span class="keyword">char</span>* m_data;	<span class="comment">// 32位，指针4Byte</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> String::String(<span class="keyword">const</span> <span class="keyword">char</span>* cstr)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (cstr)   <span class="comment">// 传入字符串，不是0</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 最后一位有标识符号</span></span><br><span class="line">        m_data = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="built_in">strlen</span>(cstr)+<span class="number">1</span>]; </span><br><span class="line">        <span class="built_in">strcpy</span>(m_data, cstr);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;  <span class="comment">//没有传入字符串</span></span><br><span class="line">        m_data = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="number">1</span>];</span><br><span class="line">        *m_data = <span class="string">'\0'</span>;     <span class="comment">// 默认只有最后的标识符</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> String::String(<span class="keyword">const</span> String&amp; str)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 深拷贝</span></span><br><span class="line">    m_data = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="built_in">strlen</span>(str.m_data)+<span class="number">1</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(m_data, str.m_data);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> String&amp; String::<span class="keyword">operator</span> = (<span class="keyword">const</span> String&amp; str)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 拷贝赋值 </span></span><br><span class="line">    <span class="comment">// 判断 两者是否指向同一内存（必须操作）</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span> == &amp;str)</span><br><span class="line">        <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 清除原指针指向</span></span><br><span class="line">    <span class="keyword">delete</span>[] m_data;</span><br><span class="line">    <span class="comment">// 重新分配内存</span></span><br><span class="line">    m_data = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="built_in">strlen</span>(str.m_data)+<span class="number">1</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(m_data, str.m_data);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> String::~String()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">delete</span>[] m_data;	<span class="comment">// 数组的分类内存，则需要delete[]</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ostream&amp; <span class="keyword">operator</span> &lt;&lt; (ostream&amp; os, <span class="keyword">const</span> String&amp; x)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> os &lt;&lt; x.get_data();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">-------------------------------</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"my_string.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">s1</span><span class="params">(<span class="string">"c++"</span>)</span></span>;</span><br><span class="line">    <span class="function">String <span class="title">s2</span><span class="params">(<span class="string">"hello"</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">String <span class="title">s3</span><span class="params">(s1)</span></span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt; s1&lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt; s2&lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt; s3&lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    s3 = s2;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt; s3&lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="Three-Stack-amp-Heap"><a href="#Three-Stack-amp-Heap" class="headerlink" title="Three. Stack &amp; Heap"></a>Three. Stack &amp; Heap</h4><ul>
<li>stack 栈：是存在于作用域中的一块内存空间。(local object / auto object)<ul>
<li>当在作用域内调用函数时，函数会形成一个stack来防治</li>
<li>当在作用域内创建新对象（局部变量），则会开辟新内来存储它，当作用域结束，则会被释放掉（调用析构函数）</li>
</ul>
</li>
<li><p>heap 堆：由操作系统提供的全局空间，动态分配。（每次分配内存，需要手动销毁）（heap object）</p>
<ul>
<li>若没有手动delete，会出现内存泄漏（memory leak）</li>
<li>对象离开作用域，指针p结束了，但指向p的对象仍然存在，没有机会去delete它了</li>
<li>new 一个对象，先是分配内存，再调用构造函数 -&gt; （c 语言）malloc(n) + 数据转型 +调用构造函数<ul>
<li>指针p为对象在内存中的起始位置，同时是类中的this</li>
</ul>
</li>
<li>delete：先调用析构函数，再释放内存 -&gt; （c 语言）调用析构函数 + free(p)</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Complex</span>&#123;</span>...&#125;;		<span class="comment">// 定义类</span></span><br><span class="line">...</span><br><span class="line"><span class="function">Complex <span class="title">c3</span><span class="params">(<span class="number">1</span>,<span class="number">2</span>)</span></span>;	<span class="comment">//global object</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="function">Complex <span class="title">c1</span><span class="params">(<span class="number">1</span>,<span class="number">2</span>)</span></span>;	<span class="comment">// c1所占用空间来自stack，离开作用域则会自动销毁</span></span><br><span class="line">    Complex* p = <span class="keyword">new</span> Complex(<span class="number">3</span>);	<span class="comment">// 由系统动态分配全局内存，离开作用域不会自动销毁，则需手动销毁</span></span><br><span class="line">    <span class="keyword">delete</span> p；</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> Complex <span class="title">c2</span><span class="params">(<span class="number">1</span>,<span class="number">2</span>)</span></span>;	<span class="comment">// static object</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>static object 静态对象：离开作用域仍然存在，直至整个程序结束</p>
<ul>
<li>静态变量或者函数只有一份内存</li>
<li>非静态函数或变量，多次被调用，则会产生多份内存</li>
<li>静态类内变量，则是所有对象共有这个静态数据（必须给它定义，<strong>类内声明，类外定义</strong>）</li>
<li><p>静态的成员函数没有 this</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Account</span>	// 银行账户类</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">double</span> m_rate;	<span class="comment">// 利率多少与用户无关，所以应该是共同一样的，因此为静态变量</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">set_rate</span><span class="params">(<span class="keyword">const</span> <span class="keyword">double</span>&amp; x)</span></span>&#123;m_rate=x;&#125; <span class="comment">// 静态变量只能由静态函数处理</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">double</span> Account::m_rate = <span class="number">8.0</span>;	<span class="comment">// 定义静态变量</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	Account::set_rate(<span class="number">5.0</span>);		<span class="comment">// 可以直接调用</span></span><br><span class="line">    </span><br><span class="line">    Account a;</span><br><span class="line">    a.set_rate(<span class="number">5.0</span>);	<span class="comment">// 对象调用</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li>global object 全局对象：作用域为整个程序，直至整个程序结束</li>
<li><p><strong>new 动态分配内存块</strong>（VC编译器）</p>
<ul>
<li><p>Cookie</p>
<ul>
<li>当在debug模式调用程序时，除了类的大小，不仅有上下两个cookie（最终大小必须是类的倍数，不足则加pad）而且会分配更多空间（方便系统回收内存）</li>
<li><p>在正常执行模式调用程序时，只有类的大小和cookie（最终大小必须是类的倍数）</p>
<p><img src="http://github.com/soloistben/images/raw/master/cplus_image/动态分配内存.png" alt="动态分配内存" style="zoom: 50%;"></p>
</li>
<li><p>程序员只看到绿色那块（类的大小），不会看到完整cookie的大小</p>
</li>
<li><strong>Cookie (16): 00000041 表示 大小为4×16=64，1表示操作系统已经分配出去</strong>（因为16进制在二进制后面四个比特位均为0），0表示已经归还给操作系统，记录了整体长度，方便程序知道回收大小</li>
</ul>
</li>
<li><p>动态分配数组<br><img src="http://github.com/soloistben/images/raw/master/cplus_image/动态分配数组内存.png" alt="动态分配数组内存" style="zoom:67%;"></p>
<ul>
<li>3 表示数组大小</li>
<li>数组的分类内存，则需要delete[]，（系统才知道删除的是个数组），否则会出错<br><img src="http://github.com/soloistben/images/raw/master/cplus_image/删除数组.png" alt="删除数组" style="zoom:75%;"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Four-Object-Oriented-Programming-OOP-Object-Oriented-Design-OOD"><a href="#Four-Object-Oriented-Programming-OOP-Object-Oriented-Design-OOD" class="headerlink" title="Four. Object Oriented Programming (OOP), Object Oriented Design (OOD)"></a>Four. Object Oriented Programming (OOP), Object Oriented Design (OOD)</h4><ul>
<li><p>类与类之间的关系</p>
<ul>
<li><p><strong>Inheritance</strong> 继承（<strong>is a</strong>）</p>
<ul>
<li><p>public, protected, private 三种继承（Java只有public继承）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>：<span class="title">public</span> <span class="title">Base</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code>+ 父类所有参数和函数都被继承（Derived(子类)包含Base(父类)）
+ 构造函数：先Base的默认构造函数（若没有默认的，并且多个构造函数，则需要表明用哪个构造函数），再Derived构造函数（由内而外）
+ 析构函数：先Derived析构函数，再Base析构函数（由外而内）
+ base class 的析构函数必须是**virtual function（虚函数）**，否则出现undefined behavior
  + 在成员函数前加上virual，就变成成员函数
  + 父类中函数，继承的是调用权
  + non-virtual函数：不希望子类override（重新定义）该函数
  + virtual函数：希望子类override（重新定义）该函数，并且默认有一个定义（空函数也是定义的一种）
+ pure virtual 函数：希望子类必须override（重新定义）该函数，默认没有定义

    <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Shape</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span> <span class="keyword">const</span></span>=<span class="number">0</span>;	<span class="comment">// pure virtual</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">error</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; msg)</span></span>;	<span class="comment">// impure virtual</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">ObjectID</span><span class="params">()</span> <span class="keyword">const</span></span>;	<span class="comment">// non-virtual</span></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre><ul>
<li><strong>Composition</strong> 复合 （<strong>has a</strong> 包含）    <ul>
<li>class A 内部定义 class B的对象（表示 class A has a class B）</li>
<li>class A is Container 容器, class B is Component 组件（A 包含B）</li>
<li>构造函数：先Component的默认构造函数（若没有默认的，并且多个构造函数，则需要表明用哪个构造函数），再Container构造函数（由内而外）</li>
<li>析构函数：先Container析构函数，再Component析构函数（由外而内）</li>
</ul>
</li>
<li><strong>Delegation</strong> 委托 （<strong>Composition by Reference</strong>）<ul>
<li>class A 内部定义 class B的对象指针</li>
<li>需要用class B的对象时，才会去创建它，不像Composition一样同步创建class对象<ul>
<li>Composition：当A对象复制三遍，则三个A对象分别创建三个不同B对象</li>
<li>Delegation：当A对象复制三遍，则三个A对象指向同一个B对象，则可以节省空间（共享内存）<ul>
<li>共享内存：不能轻易发生修改</li>
<li>当需要修改其中一个A对象时，拷贝一个B对象，再修改；剩下两个A对象共享原本的B对象（copy on write, COW）</li>
</ul>
</li>
</ul>
</li>
<li>书写风格：Handle/Body（pimlp）：Container当成外部接口，Composition当成内部操作</li>
<li><strong>Inheritance + Compsition</strong></li>
</ul>
</li>
<li>子类中继承了父类，子类又有复合，构造函数顺序为父类、复合、子类</li>
<li>子类中继承了父类，父类又有复合，构造函数顺序为复合、父类、子类<ul>
<li><strong>Delegation + Inheritance</strong>（最强组合）</li>
</ul>
</li>
<li><p>一份数据，多种表现</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Subject</span></span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">      <span class="keyword">int</span> m_value;</span><br><span class="line">      <span class="built_in">vector</span>&lt;Observer*&gt; m_views;	<span class="comment">// Delegation 委托</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">      <span class="function"><span class="keyword">void</span> <span class="title">attach</span><span class="params">(Observer* obs)</span></span></span><br><span class="line"><span class="function">      </span>&#123;</span><br><span class="line">          m_views.push_back(obs);</span><br><span class="line">  	&#125;</span><br><span class="line">      <span class="function"><span class="keyword">void</span> <span class="title">set_val</span><span class="params">(<span class="keyword">int</span> value)</span></span></span><br><span class="line"><span class="function">      </span>&#123;</span><br><span class="line">          m_value = value;	<span class="comment">// 一旦数据改变</span></span><br><span class="line">          notify();	<span class="comment">// 通知所有数据的可视化</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function"><span class="keyword">void</span> <span class="title">notify</span><span class="params">()</span></span></span><br><span class="line"><span class="function">      </span>&#123;</span><br><span class="line">          <span class="comment">// 将所有可视化遍历更细显示的数据值</span></span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;m_views.size(); ++i)</span><br><span class="line">              m_views[i] -&gt; update(<span class="keyword">this</span>, m_value);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Observer</span>	// 可以被 <span class="title">Inheritance</span> 继承，形成多种数据可视化</span></span><br><span class="line"><span class="class">  &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">      <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(Subject* sub, <span class="keyword">int</span> vlaue)</span></span>=<span class="number">0</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>Composite <a href="https://www.bilibili.com/video/BV1gb411g7pa?p=13" target="_blank" rel="noopener">video</a></li>
<li>Prototype (在父类可以创建未来的派生子类；子类创造自己，委托给父类) </li>
</ul>
<h4 id="Five-Generic-Programming"><a href="#Five-Generic-Programming" class="headerlink" title="Five.  Generic Programming"></a>Five.  Generic Programming</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/11/17/C-plus-note/" data-id="cknipj2ox0009j0egjijkw6a3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/">C++</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-EM" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/06/EM/" class="article-date">
  <time datetime="2020-10-06T13:07:10.000Z" itemprop="datePublished">2020-10-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/06/EM/">EM</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/10/06/EM/" data-id="cknipj2op0004j0eg6xifgc7p" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hidden-Markov-Model" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/06/Hidden-Markov-Model/" class="article-date">
  <time datetime="2020-10-06T12:55:04.000Z" itemprop="datePublished">2020-10-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/06/Hidden-Markov-Model/">Hidden_Markov_Model</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li><p><strong>Hidden Markov Model = Markov Random Field + Time</strong> </p>
<ul>
<li>动态模型=概率图模型+时间（可以是真正的时间，也可以是序列）</li>
<li><p>GMM高斯混合模型（样本之间独立同分布）；但是动态模型，样本之间不是独立同分布</p>
<p><img src="https://github.com/soloistben/images/raw/master/HMM/HMM1.png" alt="HMM1" style="zoom: 67%;"></p>
</li>
<li><p>图中动态模型包括：横向的时间关系（Time），纵向的混合关系（Mixture，不同变量混合）</p>
</li>
<li><strong>若hidden variable是离散的，则动态模型为HMM</strong>；线性连续的，则是Kalmm Filter 卡尔曼滤波器；非线性连续的，则是Partide Filter</li>
</ul>
<p><img src="https://github.com/soloistben/images/raw/master/HMM/HMM2.png" alt="HMM2" style="zoom:75%;"></p>
</li>
<li><p>HMM: param λ = (π, A, B)（π是初始概率分布、A转移矩阵、发射矩阵）</p>
<ul>
<li><strong>observed variable O</strong>: o~1~, o~2~, …, o~t~,… → V = {v~1~, …v~M~} （观察值，观测变量o的值域）</li>
<li><strong>hidden variable I</strong>: i~1~, i~2~, …, i~t~,… → Q = {q~1~, …q~N~} （隐变量i的值域）</li>
<li>$A = [a<em>{ij}], a</em>{ij} = P(i<em>{t+1}=q</em>{j}|i<em>{t}=q</em>{i})$</li>
<li>$B = [b<em>{j(k)}], b</em>{j(k)} = P(o<em>{t}=v</em>{k}|i<em>{t}=q</em>{j})$</li>
</ul>
</li>
<li>两个假设<ul>
<li>齐次马尔可夫假设<ul>
<li>$P(i<em>{t+1}|i</em>{t}, i<em>{t-1}, …, i</em>{1}, o<em>{t}, o</em>{t-1}, …, o<em>{1}) = P(i</em>{t+1}|i_{t})$</li>
<li>隐状态i~t+1~只与隐状态i~t~有关</li>
</ul>
</li>
<li>观测独立假设<ul>
<li>$P(o<em>{t}|i</em>{t}, i<em>{t-1}, …, t</em>{1}, o<em>{t-1}, …, o</em>{1}) = P(o<em>{t}|i</em>{t})$</li>
<li>观测状态o~t~只与观测状态i~t~有关</li>
</ul>
</li>
</ul>
</li>
<li><p>HMM解决三个问题（已知参数 λ = (π, A, B)）</p>
<ul>
<li>Evalution → P(O|λ) （已知参数下，求解O现象的概率）→ 前向后向算法</li>
<li>Learning → 求解参数，λ = argmax P(O|λ) → EM算法（以前是Baum Welch算法）</li>
<li>Decoding → 找到一个状态序列，使 P(I|O)达到最大（I～ = argmax P(I|O)）<ul>
<li>预测问题：$P(i<em>{t+1}|o</em>{1},…,o<em>{t-1}, o</em>{t})$ 已知t个观察序列，预测下一时刻t+1的隐状态</li>
<li><strong>滤波问题</strong>：$P(i<em>{t}|o</em>{1},…,o<em>{t-1}, o</em>{t})$ 已知t个观察序列，求解当前时刻t的隐状态</li>
</ul>
</li>
</ul>
<p><a href="https://www.bilibili.com/video/BV1aE411o7qd?p=82" target="_blank" rel="noopener">白板系列</a></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/10/06/Hidden-Markov-Model/" data-id="cknipj2pk000nj0eg061gbko7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-PGM-Inference" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/06/PGM-Inference/" class="article-date">
  <time datetime="2020-10-06T07:09:49.000Z" itemprop="datePublished">2020-10-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/06/PGM-Inference/">PGM_Inference</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>Inference 推断 → 求概率<ul>
<li>P(X) = P(x~1~, x~2~, …, x~p~)</li>
<li>边缘概率：$P(x<em>{i}) = Σ</em>{1}…Σ<em>{i-1} Σ</em>{i+1}…Σ_{p} P(X) $（除了i的都积分）</li>
<li>条件概率：$P(x<em>{a}|x</em>{b}),(x=x<em>{a}\bigcup x</em>{b})$</li>
<li>最大后验 MAP Inference：$\hat{Z} = argmaxP(Z|X) \propto argmax P(Z,X)$（贝叶斯定理）（不一定直接求后验，只要得到最大即$\hat{Z}$可）</li>
</ul>
</li>
<li>方法<ul>
<li>精确推断<ul>
<li>Variable Elimination (VE) 变量消除法</li>
<li><strong>Belief Propagation</strong> (BP) 信念传播（与反向传播不一样）（弥补VE缺点）<ul>
<li>另外一个名称：Sum-Product Algorithm</li>
<li>针对树结构</li>
</ul>
</li>
<li>Junction Tree Algorithm<ul>
<li>基于BP，由树结构扩展到普通图结构</li>
</ul>
</li>
</ul>
</li>
<li>近似推断<ul>
<li>Loop Belief Propagation<ul>
<li>基于BP，针对有环图</li>
</ul>
</li>
<li>Mente Carlo Inference<ul>
<li>Importance Sampling</li>
<li>MCMC (Markov Chain Mente Carlo)</li>
<li>基于采样</li>
</ul>
</li>
<li>Variational Inference<ul>
<li>确定性近似</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="Variable-Elimination"><a href="#Variable-Elimination" class="headerlink" title="Variable Elimination"></a>Variable Elimination</h5><p><img src="https://github.com/soloistben/images/raw/master/PGM_Inference/VE1.png" alt="VE1" style="zoom:75%;"></p>
<ul>
<li>假设a,b,c,d均为二值的随机变量{0,1}</li>
<li>$P(d) = Σ<em>{a,b,c} P(a,b,c,d) = Σ</em>{a,b,c} P(a)P(b|a)P(c|b)P(d|c)$ （将各个条件概率看成因子）<ul>
<li>→ P(a=0)P(b=0|a=0)P(c=0|b=0)P(d|c=0) + P(a=1)P(b=0|a=1)P(c=0|b=0)P(d|c=0) +…+ P(a=1)P(b=1|a=1)P(c=1|b=1)P(d|c=1) = 8*因子积</li>
<li>由于马尔可夫的性质，结点只与相邻的相关，与其他无关，可以优先将有关的先合并。</li>
<li>→ $Σ<em>{b,c} P(c|b)P(d|c) Σ</em>{a} P(a)P(b|a)$（$Σ<em>{a} P(a)P(b|a) = Σ</em>{a} P(a,b) = P(b)$， <strong>将P(a)看成一个函数Φ(a)，P(b|a)看成Φ(a,b)，则Σ~a~ P(a)P(b|a)看成Φ~a~(b)</strong>）</li>
<li>→ $Σ<em>{c} P(d|c) Σ</em>{b}P(c|b)Φ<em>{a}(b) = Σ</em>{c} P(d|c) Φ<em>{b}(c) = Φ</em>{c}(d)$</li>
</ul>
</li>
<li>若是无向图，则为 $P(a,b,c,d) = \frac{1}{Z}\prod Φ(x)$</li>
<li>主要思想：乘法分配律（ab+ac=a(a+c)）</li>
<li>缺点：1、重复计算（求另外一个点时，则需要重新求（则没有存储中间结果，若是链很长，则计算量很大））；2、消去次序（一般相关最少的先消去，但在无向图找到最优消去次序是NP-Hard问题）</li>
</ul>
<h5 id="Belief-Propagation"><a href="#Belief-Propagation" class="headerlink" title="Belief Propagation"></a>Belief Propagation</h5><ul>
<li></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/10/06/PGM-Inference/" data-id="cknipj2pe000jj0egkef5lyop" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Exponential-Family-Distribution" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/05/Exponential-Family-Distribution/" class="article-date">
  <time datetime="2020-10-05T08:43:34.000Z" itemprop="datePublished">2020-10-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/05/Exponential-Family-Distribution/">Exponential_Family_Distribution</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="指数族分布"><a href="#指数族分布" class="headerlink" title="指数族分布"></a>指数族分布</h4><ul>
<li>Gaussian Distribution, Bernoulli Distribution (Categorical Distribution), Binomial Distribution (Multinomial Distribution), Poisson Distribution, Beta Distribution, Dirichlet Distribution, Gamma Distribution</li>
<li><font color="red">$P(x|η) = h(x) e^{η^{T} Φ(x) - A(η)}$</font> （分为三部分）<ul>
<li>η属于参数、p维向量；A(η): log partition function（配分函数）；h(x)与η无关，往往设置为1</li>
<li>partition function（源自于统计物理学）：$P(x|θ) = \frac {1}{Z} \hat{P}(x|θ)$ （Z为归一化因子，$Z=\int \hat{P}(x|θ) d_{x}$）</li>
<li>$P(x|η) = \frac {1}{e^{A(η)}} h(x) e^{η^{T} Φ(x)} → e^{A(η)} = Z → A(η) = log Z$，所以A(η)是log partition function</li>
</ul>
</li>
<li>特点<ul>
<li><strong>充分统计量 sufficient statistics</strong>：Φ(x)<ul>
<li>统计量：对样本的加工，关于样本的一个函数，均值、方差等</li>
<li>充分：统计量就可以完整表达样本特征信息了</li>
<li>Online Learning （可以仅存储样本统计量信息，就不需要存储大量样本，起到压缩数据的效果）</li>
</ul>
</li>
<li><strong>共轭</strong><ul>
<li>$P(Y|X) = \frac{P(X|Y)P(Y)}{\int P(X|Y)P(Y) d_{Y}}$（后验概率是求不出来，或者积分难问题，太复杂，难以求解）</li>
<li>计算f(Y)后验分布的期望：近似推断（变分推断、MCMC）</li>
<li>若似然P(X|Y)与先验P(Y)共轭（如二项分布和Beta分布），则后验与先验同分布，则仅需算后验分布的参数即可，就可以不用计算积分</li>
</ul>
</li>
<li><strong>最大熵</strong>（无信息先验）<ul>
<li>没有先验，则认为是所有样本等概率，但无法定量分析，则引入最大熵</li>
<li>赋予先验：共轭（为了计算方便）；最大熵（无信息先验）</li>
</ul>
</li>
</ul>
</li>
<li>模型和推断<ul>
<li><strong>广义线性模型</strong><ul>
<li>目标：解决分类、回归问题</li>
<li>线性组合（w^T^x）</li>
<li>link function（激活函数的反函数）</li>
<li>指数族分布（y|x ~ 指数族分布）（如线性回归：y|x ~ N(μ,σ^2^)；线性分类：y|x ~ 0/1分布（Bernoulli））</li>
</ul>
</li>
<li><strong>概率图模型</strong><ul>
<li>无向图：RBM 波尔兹曼机</li>
</ul>
</li>
<li><strong>变分推断</strong><ul>
<li>指数族分布可以简化变分推断</li>
</ul>
</li>
</ul>
</li>
<li>Gaussian Distribution<ul>
<li>$P(x|θ) = \frac{1}{\sqrt{2\pi}σ} e^{\frac{(x-μ)^2}{-2σ^2}},θ=(μ,σ^2)$  一维高斯分布<ul>
<li>η = η(θ)，A(η) = A(η(θ))，将θ映射成η​</li>
<li>$P(x|\theta) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2\sigma^2}(x^2-2\mu x+\mu ^2)} = e^{-\frac{1}{2}log^{2\pi \sigma^2}} e^{-\frac{1}{2\sigma^2} {\begin{bmatrix} -2\mu \ 1 \end{bmatrix}}{\begin{bmatrix}x \ x^2 \end{bmatrix}} -\frac{\mu^2}{2\sigma^2}} \ = exp({\begin{bmatrix} \frac{\mu}{\sigma^2} \ \frac{-1}{2\sigma^2} \end{bmatrix}}{\begin{bmatrix}x \ x^2 \end{bmatrix}} - (\frac{\mu^2}{2\sigma^2} + \frac{1}{2} log^{2\pi \sigma^2}))$<ul>
<li>$η^T = {\begin{bmatrix}\frac{μ}{σ^2}\ \frac{-1}{2σ^2} \end{bmatrix}}, Φ(x) = {\begin{bmatrix}x \ x^2 \end{bmatrix}}, A(η)=\frac{μ^2}{2σ^2}+ \frac{1}{2} log^{2\piσ^2}$</li>
<li>设定$η={\begin{bmatrix}η \ η^2 \end{bmatrix}}$，则$A(η) = -\frac{η_1^2}{4η_2}+\frac{1}{2}log^{-\frac{\pi}{η_2}}$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>充分统计量Φ(x) 与 对数配分函数A(η)</strong> <ul>
<li>P(x|η) 概率积分为1</li>
<li>$P(x|η) = \frac{1}{e^{A(η)}}h(x)e^{η^T Φ(x)}→e^{A(η)}=\int h(x)e^{η^TΦ(x)}d_x$</li>
<li>两边对η求导：$e^{A(η)}*A’(η) = \frac{d(\int h(x)e^{η^TΦ(x)}d<em>{x})}{dη}=\int h(x) Φ(x)e^{η^TΦ(x)}d</em>{x}$</li>
<li>$A’(η) =\int h(x) Φ(x)e^{η^T Φ(x)-A(η)}d<em>{x}=\int Φ(x)P(x|η)d</em>{x} = E_{P(x|η)}[Φ(x)]$</li>
<li>$A’’(η)=Var_{P(x|η)} [Φ(x)]$，则A(η)是一个凸函数</li>
</ul>
</li>
<li><p><strong>充分统计量Φ(x) 与 极大似然估计</strong></p>
<ul>
<li>Data: D = {x~1~,x~2~,…,x~N~} N个样本</li>
<li>$η_{MLE}=argmax \ log^{P(D|η)}=argmax \ log^{\prod P(x_i|η)}=argmax \sum log^{P(x_i|η)} \ = argmax \sum log^{h(x_i)e^{η^T Φ(x_i)-A(η)}} = argmax \sum [log^{h(x_i)}+η^T Φ(x_i)-A(η)]$<ul>
<li>$→ η_{MLE} ∝argmax \ \sum [η^T Φ(x_i)-A(η)]$</li>
<li>$\frac{d(Σ [η^T Φ(x<em>i)-A(η)])}{dη} =\sum \frac{d(η^T Φ(x_i)-A(η))}{dη}=\sum[Φ(x_i)-A’(η)] =\sum Φ(x_i)- N*A’(η)=0 \ → A’(η</em>{MLE})=\frac{1}{N}\sum Φ(x_i)$</li>
<li>$η<em>{MLE} = A’^{(-1)}(η</em>{MLE})$（反函数） → 则η~MLE~是可求解的，只需要记录即$\frac{1}{N}\sum Φ(x_i)$可，不需要记录所有样本</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>最大熵角度</strong></p>
<ul>
<li>若一个事件发生概率为p，其信息量为-log p （若p=1,信息量就为0；一个确定的事件没有信息量）</li>
<li>熵：$E[-log^p]=\int -p(x)log^{p(x)} d_{x}=-\sum p(x)log^{p(x)}$ （对信息的衡量，对信息可能性的衡量）（熵只与x的分布有关，与取值无关）</li>
<li>最大熵&lt;=&gt;等可能（利用最大熵对等可能定量分析）（最大熵，对未知的分布进行猜测，因为不知道，所以认为都是等可能的）（<strong>要想熵最大，未知的分布必须是等可能</strong>）<ul>
<li>$H[p]=-\sum p(x)log^{p(x)}$</li>
<li>假设x是离散的，P(x=1) = p~1~，P(x=2) = p~2~，…，P(x=k) = p~k~，Σp~i~ = 1</li>
<li>则 $max \ H[P] = max[-\sum p_i log^{p_i}],s.t.\sum p_i=1$</li>
<li>$\hat{p_i} = argmax \ H[P] = argmin \ \sum p_i log^{p_i}$ （优化问题）</li>
<li>拉格朗日：$L(p, λ) = \sum p_i log^{p_i} - λ(1- \sum p_i)，\frac{dL}{dp_i} = log^{p_i} + 1 - λ = 0 → p_i = e^{λ-1}$ (常数)</li>
<li>则 p~1~ = p~2~ = … p~k~ = 1/k，p(x)是了离散型均匀分布</li>
</ul>
</li>
<li>最大熵原理：<strong>在满足已知事实（约束条件）（已知数据）下，什么分布是具有最大熵的分布</strong><ul>
<li>Data = {x~1~,x~2~,…,x~N~} 通过经验分布（概率分布$\hat{P}(X=x) = \hat{p}(x) = \frac{count(x)}{N}$）定量描述数据</li>
<li>需要P分布的$E<em>{\hat{p}}[x], Var</em>{\hat{p}}[x]$，设定f(x)是任意关于x的向量函数（$f=[f<em>1,f_2,…,f_Q]^T$），则$E</em>{\hat{p}}[f(x)]=Δ$（即是已知事实）</li>
<li>$P(X)→p(x),H[p]=-\sum p(x)log^{p(x)}$<br>$= argmin ∑ p(x)log^{p(x)}, s.t.∑p(x)=1,E<em>p[f(x)]=∑p(x)f(x)=E</em>{\hat{p}}[f(x)]=Δ $</li>
<li>拉格朗日：$L(p, λ_0, λ) = \sum p(x)log^{p(x)} - λ_0(1- \sum p(x)) - λ^T(Δ - \sum p(x)f(x))$</li>
<li>求导：$\frac{dL}{d_{p(x)}} = \sum [log^{p(x)} + 1] - \sum λ_0 - \sum λ^T f(x) = Σ[log^{p(x)}+1-λ_0-λ^T f(x)] = 0 \ \rightarrow log^{p(x)}+1-λ_0-λ^T f(x)=0 →p(x) = e^{λ^T f(x) - (1-λ_0)}$</li>
<li>令η=λ^T^，Φ(x)=f(x)，A(η)=(1-λ~0~)</li>
<li>则用最大熵原理推出，p(x)是指数分布时熵最大</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/10/05/Exponential-Family-Distribution/" data-id="cknipj2p0000aj0eg65fsgjsp" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Dimensionality-Reduction" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/02/Dimensionality-Reduction/" class="article-date">
  <time datetime="2020-10-02T13:10:36.000Z" itemprop="datePublished">2020-10-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/02/Dimensionality-Reduction/">Dimensionality_Reduction</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li><p>过拟合</p>
<ul>
<li>解决方法：增加数据、正则化、降维</li>
<li><p>原因：<strong>维度灾难</strong></p>
<ul>
<li>在没有很多数据集时，只能降维</li>
<li>每增加一维，二值的特征，都是2的指数倍增长，要想覆盖所有样本空间，则需要2的指数倍数据才可以（而且往往不只是二值）</li>
<li><p>从几何层面看：</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/Dimensionality_Reduction/DR1.png" alt="DR1" style="zoom: 33%;"></p>
<ul>
<li>2维正方形面积：1，圆形：$\pi*(0.5)^2$</li>
<li>3维正方体体积：1，球体体积：$\frac{4}{3}<em>\pi</em>(0.5)^3 = K*(0.5)^3$</li>
<li>D维超立方体体积：1，超球体体积： $K*(0.5)^D$</li>
<li><p>D趋向无穷大之后，超球体体积约等于0，则为空心的，则数据分布在超立方体的四角，造成了样本数据十分稀疏且分布不均匀，因此很难分类</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/Dimensionality_Reduction/DR2.png" alt="DR2" style="zoom:33%;"></p>
</li>
<li><p>D维外超球体体积：$K*1^D = K$，环形体积：外超球体体积 - 内超球体体积 = $K - K(1-e)^D$</p>
<ul>
<li>V外/V内  $=1-(1-e)^D  =1$（$0&lt;e&lt;1$，D趋向无穷大之后，$(1-e)^D$趋向于0）</li>
<li>则无论e多小，在高维空间，环形体积约等于1，内超球体为空心，数据分布在外超球体壳上</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Data<ul>
<li>N个p维样本 X（维度N×p）（设$I$为N维全1列向量）</li>
<li>样本均值 $\hat{X}=\frac{1}{N} \sum x_i = \frac{1}{N} X^T I$（维度p×1）</li>
<li>方差 $S = \frac{1}{N} \sum (x_i - \hat{X})(x_i - \hat{X})^T = \frac{1}{N} X^T (I - \frac{1}{N} I I^T) (1-\frac{1}{N} I I^T)^T X = \frac{1}{N} X^T H H^T X = \frac{1}{N} X^T H X$<ul>
<li>（维度p×p）</li>
<li>$H =  I-\frac{1}{N} I I^T$  centering matrix（将数据平移转换，数据分布在坐标中心）（维度N×N）</li>
<li>$H^T = H, H^2 = H H^T = (I-\frac{1}{N}I I^T) (I-\frac{1}{N} I I^T)^T = I-\frac{1}{N} I I^T = H$</li>
<li>$H^n = H$</li>
</ul>
</li>
</ul>
</li>
<li><p>降维方法</p>
<ul>
<li>直接降维 （特征选择：人工选取重要特征 ）</li>
<li><p>线性降维</p>
<ul>
<li><p><strong>Principal Components Analysis PCA 主成分分析</strong></p>
<ul>
<li><p>将线性相关的特征通过正交变换为线性无关（对原始特征空间的重构）（线性相关（存在2个以上特征之间联系））</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/Dimensionality_Reduction/DR3.png" alt="DR3" style="zoom: 67%;"></p>
</li>
<li><p>最大投影方差</p>
<ul>
<li>找到一个u~1~平面，使投影间距达到最大（投影到u~2~平面，距离太小，没有意义）<ul>
<li>这个平面就是主成分（线性无关的基(特征向量)为数据中的主要成分，降到k维，则选取第k大的特征值所对应的特征向量）</li>
<li>第1步：中心化：先将所有数据平移，利于计算，即 $x_i - \hat{X}$</li>
<li>第2步：投影到u~1~平面：$(x_i - \hat{X})^T u_1$（设定 $|u_1|=1$，即$u_1^T u_1=1$）</li>
<li>第3步：投影方差$ J = \frac{1}{N} \sum [(x_i - \hat{X}^T u_1]^2 = \frac{1}{N} \sum [u_1^T (x_i - \hat{X}) (x_i - \hat{X})^T u_1] = u_1^T S u_1$</li>
</ul>
</li>
<li>$\hat{u_1} = argmax \ u_1^T S u_1,s.t. u_1^T u_1=1$<ul>
<li>使用拉格朗日求解</li>
<li>$L(u_1, λ) = u_1^T S u_1 + λ(1-u_1^T u_1)$</li>
<li>$\frac{dL}{du_1} = 2 S u_1 - 2λ u_1 = 0 → S u_1 = λ u_1$ </li>
<li><strong>u~1~为eigen-vector特征向量，λ为eigen-value特征值</strong></li>
<li>解法1：对方差矩阵特征分解，即可求解PCA</li>
<li>解法2：直接对原始数据进行操作：中心化后的 $HX = UΣV^T$ 进行奇异值分解（U和V均为正交矩阵），$S = X^T H X = X^T H^T H X = (VΣU^T)(UΣV^T) = V Σ^2 V^T$（可先忽略1/N常数）（维度p×p），因此直接求解HX奇异值分解，也就是求解了S的特征分解</li>
<li>假设 $B = H X X^T H = (UΣV^T)(VΣU^T) = U Σ^2 U^T$（维度N×N），则B与S有一样的eigenvalue，（S特征分解得到方向V（主成分）然后通过$HX V$得到新坐标）（B特征分解直接得到坐标U，称为主坐标分析 <strong>principal coordinate analysis PCoA</strong>）</li>
<li>$HX V = UΣV^T V = UΣ$（UΣ是坐标矩阵），$BUΣ = U Σ^2 U^T UΣ = UΣ Σ^2$（UΣ是特征向量组成的矩阵）</li>
</ul>
</li>
</ul>
</li>
<li>最小重构代价<ul>
<li>投影在u~1~平面的点恢复到原来样子的代价</li>
<li>设从原p维降到q维（下面u代表特征）<ul>
<li>$x_i = \sum_k^p (x_i^T u_k) u_k, \hat{x_i} =  \sum_k^q (x_i^T u_k) u_k$  (用特征$u_k$描述样本$x_i$，$x_i^T u_k$为距离大小，$u_k$为单位大小，则第k维描述为$(x_i^T u_k) u_k$)</li>
<li>代价函数 $L =\frac{1}{N} \sum||x<em>i - \hat{x_i}||^2 = \sum</em>{k=q+1}^p u<em>k^T S u_k  = \sum</em>{k=q+1}^p λ_k, s.t. u_k^T u_k=1$</li>
<li>$u_k = argmin \ L$ </li>
</ul>
</li>
</ul>
</li>
<li>概率角度<ul>
<li>P-PCA<ul>
<li>设定observed data X为p维（特征为连续型数据），latent variable Z为q维（q&lt;p）</li>
<li>设定$Z$~$N(0, I)$（服从高斯分布，q维）</li>
<li>$X = WZ + u + ε$​（X是Z的一个线性变换加噪声）</li>
<li>$X|Z$~$N(WZ + u, σ^2 I)，X~N(u, WW^T+σ^2 I)$</li>
<li>噪声$ε$~$N(0, σ^2 I)$（p维）</li>
<li>这也是一种Linear Gaussian Model（称该模型各向同性，对各方向影响是一样的）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>求P(Z), P(X|Z), P(X), 最后求后验P(Z|X)、用EM求参数W, u, σ</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/Dimensionality_Reduction/DR4.png" alt="DR4" style="zoom:75%;"></p>
<pre><code>  + 从服从高斯分布的Z中，投影点在方向W，进行线性变换得到X，也得到服从高斯分布的X|Z，方向W上有很多的高斯分布（各向同性）；X的分布不在方向W上，且中间很宽（因为高斯分布中间高两边低）[详情](https://www.bilibili.com/video/BV1aE411o7qd?p=27)
</code></pre><ul>
<li>MDS<ul>
<li>非线性降维</li>
</ul>
</li>
<li>流型</li>
<li>Isomap</li>
<li>LLE</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/10/02/Dimensionality-Reduction/" data-id="cknipj2os0005j0eg9bwgbvm5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-SVM" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/02/SVM/" class="article-date">
  <time datetime="2020-10-02T08:50:04.000Z" itemprop="datePublished">2020-10-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/02/SVM/">SVM</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>Data : N个p维样本 X（维度N×p），y = {-1,1}</li>
<li><p>SVM 三宝：间隔，对偶，核技巧</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM1.png" alt="SVM1" style="zoom:50%;"></p>
</li>
<li><p>提出SVM是为了解决二分类问题；成功分类的直线（平面）有无数个，SVM就要找到最优的结果（即<strong>所有样本距离平面都足够大</strong>）</p>
</li>
<li><p><strong>hard-margin SVM</strong>（硬间隔）</p>
<ul>
<li>最大间隔分类器 $= max \ margin(w, b),s.t. y_i(w^T x_i+b) &gt; 0,for i = 1,…,N$</li>
<li>点到直线距离，垂直线最短</li>
<li>$margin(w, b) = min \ distance(w, b, x_i) = min \ \frac{1}{||w||} |w^T x_i + b|$</li>
<li>$→ max<em>{w,b} \ min_x \frac{1}{||w||} |w^T x_i + b|,(s.t. y_i(w^T x_i+b) &gt; 0)=max</em>{w,b} \frac{1}{||w||} min_x y_i(w^T x_i + b)$ (存在$r&gt;0$，使$y_i(w^T x_i + b) =r$，可以设置$r=1$)</li>
<li>$→ max \ \frac{1}{||w||} ,s.t. min \ y_i(w^T x_i + b) = 1 → min \ \frac{1}{2} w^T w , s.t. y_i(w^T x_i + b)\geqslant 1$(convex optimization 二次凸优化问题)(primal problem原问题)</li>
<li>拉格朗日：$L(w, b, λ) = \frac{1}{2} w^T w + \sum λ_i(1-y_i(w^T x_i + b)) (λ_i \geqslant  0, (1-y_i(w^T x_i + b)) \leqslant 0$；若$(1-y_i(w^T x_i + b))&gt;0$，L为正无穷，无解；仅在 $λ_i=0， (1-y_i(w^T x_i + b)) =0$，达到最大L)</li>
<li><strong>primal problem 原问题</strong>&lt;=&gt; $min<em>{w,b} \ max</em>λ \ L(w, b, λ),s.t. λ_i \geqslant 0$ （对w，b没有限制）$→ min \ \frac{1}{2} w^T w$</li>
<li><p><strong>dual problem 对偶问题</strong>：$max<em>λ \ min</em>{w,b} \ L(w, b, λ),s.t. λ_i \geqslant 0$</p>
<ul>
<li>min max L &gt;= max min L 弱对偶关系（鸡头凤尾），若直接相等，则为强对偶关系</li>
<li>（若L问题是二次凸优化问题，则min max L = max min L为强对偶关系）</li>
<li>$\frac{dL}{db} = \frac{d[\sum λ_i(1-y_i(w^T x_i + b))]}{db} = \frac{d[- Σ λ_i y_i b]}{db} = -\sum λ_i y_i =0$，带入原式$L = \frac{1}{2} w^T w + \sum λ_i - \sum λ_i y_i w^T x_i$</li>
<li>$\frac{dL}{dw} = w - \sum λ_i y_i x_i = 0  → w = \sum λ_i y_i x_i$，带入原式$L=\frac{1}{2} w^T w + \sum λ_i - w^T w = \sum λ_i - \frac{1}{2}w^T w$</li>
<li><font color="red">$→ min \ \frac{1}{2} w^T w - \sum λ_i,s.t. λ_i\geqslant0, \sum λ_i y_i =0$</font>  （此处不能求λ偏导）</li>
<li>$→ min \ \frac{1}{2} \sum_i \sum_j λ_i λ_j y_i y_j x_i^T x_j - \sum_i λ_i,s.t. λ_i\geqslant 0, \sum λ_i y_i =0$</li>
<li><strong>KKT条件</strong>：参数偏导为0（$\frac{dL}{db}=0，\frac{dL}{dw}=0，\frac{dL}{dλ}=0$），$λ_i(1-y_i(w^T x_i + b))=0， λ_i\geqslant0，(1-y_i(w^T x_i + b)\leqslant0$</li>
<li>原问题和对偶问题具有强对偶关系&lt;=&gt;满足KKT条件</li>
<li>$\hat{w} = \sum λ_i y_i x_i$, （存在$x_k,y_k,1-y_k(w^T x_k + b)=0$）$\hat{b} = y_k - w^T x_k = y_k - (\sum λ_i y_i x_i^T) x_k$</li>
</ul>
</li>
<li><p>$f(x) = sign(\hat{w}^T x + \hat{b})$</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM2.png" alt="SVM2" style="zoom:50%;"></p>
<ul>
<li>落在虚线的样本点就是$x_k（y_k(w^T x_k + b)=1$），就称为support vector支持向量，只有支持向量对求解有意义，其他的样本点对应的λ均为0</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>soft-margin SVM</strong>（软间隔）</p>
<ul>
<li>hard-margin SVM是基于样本属于可分的，但是实际数据是存在噪声，可能导致分不好，甚至不可分</li>
<li><p>soft-margin SVM在hard-margin SVM基础上允许一点点错误，$min \ \frac{1}{2} w^T w + loss $</p>
<ul>
<li>分错点的个数：$loss = \sum I{y_i(w^T x_i + b)&lt;1}$ （关于w是不连续的，无法求导，因此不采取）</li>
<li><p>hinge 距离：$hinge \ loss = max {0, 1-y_i(w^T x_i + b)}$</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM3.png" alt="SVM3" style="zoom: 67%;"></p>
</li>
<li><p>$min \ \frac{1}{2} w^T w + C \sum max {0, 1-y_i(w^T x_i + b)},s.t. y_i(w^T x_i + b)\geqslant 1$ （超参数C）</p>
</li>
<li><p>→ 设定$ξ_i = y_i(w^T x_i + b)，min \ \frac{1}{2} w^T w + C \sum ξ_i,s.t. y_i(w^T x_i + b)\geqslant (1-ξ_i), ξ_i\geqslant 0$（同样用对偶问题方式来求解）</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM4.png" alt="SVM4" style="zoom: 50%;"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>约束优化问题</p>
<ul>
<li>primal problem 原问题：$min \ f(x),s.t. m_i(x) \leqslant 0, n_j(x)=0 (i=1,…,M, j=1,…,N)$</li>
<li>原问题的无约束形式（关于x的函数）：拉格朗日：<font color="red">$L(x, λ, η) = f(x) + \sum λ<em>i m_i(x) + \sum η_i n_i(x)  → min_x \ max</em>{λ,η} \ L(x, λ, η),s.t. λ_i\geqslant 0$</font></li>
<li>证明两者等价：如果违法约束$m<em>i(x)&gt;0，max</em>λ \ L → ∞$；反之，$max_λ \ L$ 必有最大值（$λ_i=0$时）（即排除了$m_i(x)&gt;0$情况，过滤掉违反约束的情况）</li>
<li>dual problem 对偶问题（关于λ,η的函数）：<font color="red">$max_{λ,η} \ min_x \ L(x, λ, η),s.t. λ_i\geqslant 0$</font><ul>
<li><strong>弱对偶性：对偶问题&lt;=原问题</strong> （$max<em>{λ,η} \ min_x \ L(x, λ, η)  \leqslant  min_x \ max</em>{λ,η} \ L(x, λ, η)$）</li>
<li>证明：$min<em>x \ L \leqslant L \leqslant max</em>{λ,η} \ L  →  A(λ,η) \leqslant L \leqslant B(x)  →  A(λ,η) \leqslant B(x)  →  max \ A(λ,η) \leqslant min \ B(x)$</li>
<li>$→ max<em>{λ,η} \ min_x \ L(x, λ, η) \leqslant min_x \ max</em>{λ,η} \ L(x, λ, η)$</li>
<li>（在$min_x \ L$已经确定x，则只剩下关于 λ,η的函数A，函数B同理）</li>
<li>强对偶性：对偶问题=原问题</li>
</ul>
</li>
<li><p>几何解释</p>
<ul>
<li>primal problem: $min \ f(x),s.t. m_1(x)\leqslant 0$ (D定义域，D=dom~f~ ∩ dom~m1~)， <font color="red">原问题最优解：$p^* = min f(x)$</font></li>
<li>$L(x, λ) = f(x) + λ m<em>1(x),s.t. λ\geqslant 0$ <font color="red">对偶最优解：$d^* = max</font></em>λ \ min_x \ L(x, λ)$&lt;/font&gt;</li>
<li><p>将问题投影入二维空间：引入集合(区域) $G = {(m_1(x), f(x))|x∈D}$</p>
<ul>
<li>不知道G是凸还是非凸，非凸具有一般性，则画个非凸的图像</li>
<li>凸集是指集合内任意两点的连线都在集合内</li>
<li>凸优化问题是指x是闭合的凸集且f是x上的凸函数的最优化问题，这两个条件任一不满足则该问题即为非凸的最优化问题</li>
<li>目标函数f如果不是凸函数，则不是凸优化问题</li>
<li>决策变量x中包含离散变量（0-1变量或整数变量），则不是凸优化问题</li>
<li>如果其二阶导数在区间上非负，就称为凸函数；如果其二阶导数在区间上恒大于0，就称为严格凸函数</li>
<li>结论：凸函数的局部最优解就是全局最优解</li>
</ul>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM5.png" alt="SVM5" style="zoom: 67%;"></p>
<ul>
<li><p>$p^* = inf {f(x)|(m_1(x), f(x))∈G, m_1(x) \leqslant 0}$（集合中没有最小值概念，对应的是下确界）</p>
<ul>
<li>$P*$ 对应图中蓝色部分（左半边区域对纵轴的映射），下确界则为左半边区域最低点在纵轴的映射</li>
</ul>
</li>
<li><p>$d^* = max_λ \ g(λ) , g(λ) = min_x \  f(x) + λ m_1(x) , g(λ) = inf {f(x) + λ_i m_1(x)|(m_1(x), f(x))∈G}$</p>
<ul>
<li>一条过原点直线 $f(x)+λm_1(x)= 0$(斜率λ可变)，g(λ)范围可以从直线开始与G相切到离开G相切的地方（红线范围）$g(λ)\leqslant p^*$ </li>
<li>当调整斜率$λ^<em>$，得到一个 $g(λ^</em>) = f(x) + λ^<em> m_1(x)$ 同时与G的俩角相切，此时，直线与纵轴的交点为$d^</em>$（绿线）</li>
<li><p>$d^<em> \leqslant p^</em>$ （凸优化+slater条件 → $d^<em> = p^</em>$）（SVM是二次规划问题，符合slater条件）</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM6.png" alt="SVM6" style="zoom: 67%;"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>slater条件</p>
<ul>
<li>Convex + Slater → Strong Duality （充分不必要条件）</li>
<li>定义：存在$\hat{x}$在relint，使$m_i(x)&lt;0 (i=1,…,M)$<ul>
<li>relative interior（relint）：在一个有边界的区域，relint对应其无边界的内部区域</li>
<li>仿射函数即由由1阶多项式构成的函数，一般形式为 $f (x) = Ax + b$（A 是一个 m×k 矩阵，反映了一种从 k 维到 m 维的空间映射关系，称f是仿射函数；A、x、b都是标量且b=0，f才是线性函数）</li>
</ul>
</li>
<li>对于大多数凸优化，slater是成立的（存在一些凸优化问题是不符合slater条件，没有强对偶关系的）</li>
<li>放松的slater条件：在$m_i(x)$中，若M中有k个仿射函数，则仅需校验剩余M-k个是否满足$m_i(x)&lt;0$ （凸二次规划问题：目标函数f是凸的，不等式约束$m_i$是仿射函数，等式约束$n_j$也是仿射函数；所以凸二次规划问题符合放松的slater条件，SVM属于凸二次规划问题，则可以直接使用KKT条件求解）</li>
</ul>
</li>
<li>KKT条件<ul>
<li>KKT  &lt;=&gt; Strong Duality ($d^<em> = p^</em>$)（充要条件）</li>
<li>从$p^<em>$得到最优$x^</em>$，从$d^<em>$得到$λ^</em>$、$η^*$</li>
<li>可行域（可行条件）：$m_i(x^<em>) \leqslant 0, n_j(x^</em>)=0, λ^*\geqslant 0$</li>
<li>互补松弛<ul>
<li>$d^<em> = max_{λ,η} \ g(λ,η) = g(λ^</em>, η^<em>) = min_x \ L(x, λ^</em>, η^<em>) \leqslant L(x^</em>, λ^<em>, η^</em>) \ = f(x^<em>) + \sum λ_im_i(x^</em>) + \sum η_in_i(x^<em>) = f(x^</em>) + \sum λ_im_i(x^<em>) \leqslant f(x^</em>) = p^*$</li>
<li>（$λ_i\geqslant 0，m_i \leqslant 0，则 λ_i m_i \leqslant 0$）</li>
<li><font color="red">互补松弛条件 ：$\sum λ_i m_i(x^*)  = 0 → λ_i^* m_i(x^*) $</font></li>
</ul>
</li>
<li>梯度为0<ul>
<li>$min_x \ L(x, λ^<em>, η^</em>) &lt;= L(x^<em>, λ^</em>, η^*)$</li>
<li>$x^*$是对应x最小值，则 $\frac{dL}{dx} = 0$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>kernel SVM</strong></p>
<ul>
<li>Kernel Method（思想角度）</li>
<li>Kernel Trick（计算角度）</li>
<li><p>Kernel function</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM9.png" alt="SVM9"></p>
<ul>
<li><p><strong>非线性带来高维转换（从模型角度）</strong></p>
<ul>
<li>PLA (Perceptron Learning Algorithm)通过初始化不同w、b，求得不同超平面；Hard-Margin SVM找到最好的超平面</li>
<li><p>但对数据而言是往往是包含噪声，因此需要对严格线性可分的条件放松，允许放一点点错误，获得更好的范化性能（如左图）</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM7.png" alt="SVM7" style="zoom: 50%;"></p>
</li>
<li><p>但面对右图的情况，非线性可分问题，即使允许放一点点错误，也是无法分类的。</p>
</li>
<li>对于PLA，则有多层感知机（神经网络）→深度学习 （多一层感知机，就可以更逼近一个连续函数，则可以解决非线性问题）     </li>
<li><font color="red">非线性可分问题 → Φ(x) 非线性转换到高维空间 → 线性可分问题</font>

<p><img src="https://github.com/soloistben/images/raw/master/statistics/SVM/SVM8.png" alt="SVM8" style="zoom: 67%;"></p>
</li>
<li><p>面对典型异或问题，PLA是无法解决该问题（深度学习可以），将二维空间转换为三维空间，即可用红色超平面划分（Cover Theorem：高维空间比低维更易线性可分）</p>
</li>
<li><p>三种方法转高维：1、类似MLP直接转高维；2、Kernel方法转高维；3、深度学习运用与或非构建有向无环图（神经网络）（与或非（三种基础运算均可用PLA表示）解决异或问题（复合运算）），神经网络：复合表达式、复合函数、MLP（FeedForward Neural Network）</p>
<ul>
<li><p>XOR：x~1~⊕x~2~ = (¬x~1~∧x~2~)∨(x~1~∧¬x~2~)</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/FNN/FNN1.png" alt="FNN1" style="zoom: 67%;"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>对偶表示带来内积（从优化角度）</strong></p>
<ul>
<li>从频率视角归化到优化问题</li>
<li>Hard-Margin SVM 将最大间隔分类思想，转换为凸优化问题，通过拉格朗日的对偶性简化原问题为对偶问题<ul>
<li>Doul Problem: $min \ \frac{1}{2} \sum_i \sum_j λ_i λ_j y_i y_j x_i^T x_j - \sum_i λ_i  s.t. λ_i \geqslant 0, \sum_i  λ_i y_i =0$</li>
<li>内积：$x_i^T x_j$</li>
<li>非线性转换：$Φ(x_i)^T Φ(x_j)$ （高维空间的内积形式）（现实数据很复杂，并且Φ(x)可以是无限维，因此很$Φ(x_i)^T Φ(x_j)$难i求解和计算量很大）</li>
<li>Kernel Trick: <strong>Kernel function的引入，就是为了解决计算问题，直接得到$Φ(x_i)^T Φ(x_j)$ 结果</strong>（不需要先求Φ(x)再求内积）</li>
</ul>
</li>
<li><strong>Kernel function : $K(x, x’) =  Φ(x)^T Φ(x’) = \ &lt;Φ(x), Φ(x’)&gt;$</strong> <ul>
<li>存在$x, x’∈X$，使$K(x, x’) =  Φ(x)^T Φ(x’)$，则K就是一个核函数（如$K(x, x’)=e^{\frac{-(x-x’)^2}{2σ^2}}$）</li>
<li>蕴含了：非线性转换+内积</li>
</ul>
</li>
</ul>
</li>
<li>一般核函数指<strong>正定核函数</strong> <a href="https://www.bilibili.com/video/BV1aE411o7qd?p=37" target="_blank" rel="noopener">详解</a><ul>
<li>更精确定义：K可以将任意输入空间X映射到高维空间，则K(x, x’)为核函数</li>
<li>正定核函数：K可以将任意输入空间X映射到高维空间，有K(x, x’)，存在Φ（Φ∈Hilbert Space）可以输入空间X映射到高维空间，且使$K(x, x’) = \ &lt;Φ(x), Φ(x’)&gt;$，则K(x, x’)为正定核函数</li>
<li>正定核函数（另一个定义）：K可以将任意输入空间X映射到高维空间，有K(x, x’)，若满足两个条件（对称性、正定性）则为正定和函数<ul>
<li>对称性：$K(x, x’) = K(x’, x)$</li>
<li>正定性：任取N个元素，x~1~,x~2~,…,x~N~∈X，对应的Gram矩阵是半正定的（K=[K(x~i~, x~j~)]）（两个定义等价，即证明：<strong>K(x, x’) = &lt;Φ(x), Φ(x’)&gt; &lt;=&gt; Gram matrix 半正定且对称</strong>）</li>
<li>Hilbert Space: 完备的、可能是无限维的、被赋予内积的，线性空间（向量空间，满足加法和数乘等条件）（完备是对极限是封闭的，即无论如何操作，仍然属于该空间内）（内积：对称性（<f, g=""> = <g, f="">）、正定性（内积大于等于0，<f, f=""> &gt;= 0）、线性性（<r~1~ f~1~="" +="" r~2~="" f~2~="" ,="" g=""> = r~1~ <f~1~, g=""> + r~2~ <f~2~, g="">））  </f~2~,></f~1~,></r~1~></f,></g,></f,></li>
</ul>
</li>
<li>必要性证明<ul>
<li>在Hilbert Space中的Φ(x)具有对称性性质，$K(x, x’) = &lt;Φ(x), Φ(x’)&gt; = &lt;Φ(x’), Φ(x)&gt; = K(x’, x)$</li>
<li>K=[K(x~i~, x~j~)]（维度N×N）（半正定：任意a列向量，$a^T K a \geqslant 0$）</li>
<li>$a^T K a = \sum<em>i \sum_j a_i a_j K</em>{ij} = \sum_i \sum_j a_i a_j K(x_i, x_j) = \sum_i \sum_j a_i a_j &lt;Φ(x_i), Φ(x_j)&gt; → 线性性\ → \sum_i \sum_j a_i a_j Φ(x_i)^T Φ(x_j) = \sum_i a_i Φ(x_i)^T \sum_j a_j Φ(x_j) = [\sum_i a_i Φ(x_i)]^T \sum_j a_j Φ(x_j) \ = \ &lt;\sum_i a_i Φ(x_i), \sum_j a_j Φ(x_j)&gt; \ =  ||\sum_i a_i Φ(x_i)||^2 &gt;= 0，半正定性$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/10/02/SVM/" data-id="cknipj2ps000wj0eg6zsk67sf" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Decision-Tree" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/10/02/Decision-Tree/" class="article-date">
  <time datetime="2020-10-02T08:49:49.000Z" itemprop="datePublished">2020-10-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/02/Decision-Tree/">Decision_Tree</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li><p>基于数据特征构造决策树</p>
<ul>
<li>有向边</li>
<li><p>结点</p>
<ul>
<li>内部结点(internal node)-&gt;表示特征</li>
<li><p>叶子结点(leaf node)-&gt;表示类别</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/DT1.png" alt="DT1" style="zoom:67%;"></p>
</li>
<li><p>从根结点开始，对实例的某一特征进行取得阈值，从而划分，再递归根据后续的特征，再取值划分，直至到叶子结点，完成分类</p>
</li>
</ul>
</li>
<li>决策树表示给定特征条件下类的条件概率分布。<ul>
<li>一个条概率分布定义特征空间的一个划分上</li>
<li>将特征空间划分为互不相交的单元cell，每个单元定义一个类的概率分布就构成了一个条件概率分布，则一条路径对应一个单元，构成<strong>叶子结点基于其父结点的条件概率</strong></li>
</ul>
</li>
<li>决策树能对训练数据有很好的分类，但是会造成过拟合现象，则需要剪枝，增加其泛化性，才能在测试数据达到更好效果<br><a href="https://www.cnblogs.com/pinard/p/6050306.html" target="_blank" rel="noopener">详解</a></li>
</ul>
</li>
<li><p>决策树学习过程：特征选择、决策树生成、剪枝</p>
<ul>
<li><p><strong>ID3算法</strong>（分类、多叉树）</p>
<ul>
<li><p>特征选择（在某个特征下，根据信息增益来判断数据是否更好的分类）</p>
<ul>
<li>Information Gain 信息增益。信息增益越大对应的特征越重要</li>
<li>Entropy 熵，表示随机变量不确定的度量</li>
<li><p>D表示数据集，A表示特征，Ck为第k个类别（共K类），pi为概率，H(D)表示熵，H(D|A)表示条件熵（A特征将D划分为n个子集Di），gain(D,A)表示当前特征A的信息增益（细节推导见统计学方法，第二版，75页）</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/DT2.png" alt="DT2"></p>
</li>
</ul>
</li>
<li><p>生成：选择对应最大信息增益的特征，再根据该特征将数据划分成两个子集，再其中未分好的子集中再次递归选择最大信息增益的特征</p>
</li>
<li>缺点：由于信息增益会导致偏向于选择取值较多的特征、没有考虑连续特征、没考虑缺失值</li>
</ul>
</li>
<li><p><strong>C4.5算法</strong>（分类、多叉树）</p>
<ul>
<li><p>特征选择</p>
<ul>
<li><p>Information Gain Ratio 信息增益比=信息增益 / 特征熵</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/DT3.png" alt="DT3" style="zoom: 67%;"></p>
</li>
</ul>
</li>
<li><p>生成：与ID3算法类似</p>
</li>
<li>缺点：基于信息论的熵模型的，这里面会涉及大量的对数运算</li>
<li>二叉树模型会比多叉树运算效率高</li>
<li>无剪枝</li>
</ul>
</li>
<li><p><strong>CART</strong> classification and regression tree（分类、回归、二叉树）</p>
<ul>
<li><p>分类</p>
<ul>
<li><p>特征选择</p>
<ul>
<li>Gini基尼指数</li>
<li>基尼指数Gini(D)表示集合D的不确定性，Gini(D, A)表示基于特征A 划分后D的不确定性</li>
<li>基尼指数越大，样本集合不确定性也越大（基尼指数和熵都可以近似表示分类误差率）</li>
</ul>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/DT4.png" alt="DT4"></p>
</li>
<li><p>生成</p>
<ul>
<li>根据计算现有特征对样本集合D的基尼指数，每次迭代均选择最小基尼指数对应的特征作为最优切分点</li>
<li>生成决策树之后，根据底端开始不短剪枝，直至根结点，形成子树</li>
</ul>
</li>
<li><p>损失函数</p>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/DT5.png" alt="DT5" style="zoom:75%;"></p>
<ul>
<li>T为任意子树，C(T)为对训练数据的预测误差（基尼指数），|T|为子树叶子结点个数，a为大于0的参数，Ca(T)表示了整体的损失</li>
</ul>
<p><img src="https://github.com/soloistben/images/raw/master/statistics/DT6.png" alt="DT6" style="zoom:75%;"></p>
</li>
</ul>
</li>
<li><p>回归</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/10/02/Decision-Tree/" data-id="cknipj2oi0002j0eggpm2ax08" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">下一页 &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/">ML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/basic-protein/">basic protein</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cluster/">cluster</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/ML/" style="font-size: 20px;">ML</a> <a href="/tags/basic-protein/" style="font-size: 10px;">basic protein</a> <a href="/tags/cluster/" style="font-size: 10px;">cluster</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/04/14/NLP/">NLP</a>
          </li>
        
          <li>
            <a href="/2021/04/09/Interview/">Interview</a>
          </li>
        
          <li>
            <a href="/2020/11/17/C-plus-note/">C_plus_note</a>
          </li>
        
          <li>
            <a href="/2020/10/06/EM/">EM</a>
          </li>
        
          <li>
            <a href="/2020/10/06/Hidden-Markov-Model/">Hidden_Markov_Model</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 (soloistben)<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>