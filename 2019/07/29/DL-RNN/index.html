<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>DL_RNN | MR.C</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Sequence Model 序列模型（包括RNN）：1、Speech Recognition 语音识别：输入一段语音，输出英文句子（输入输出都属于Sequence Data序列数据）2、Music generation 音乐生成：输入可以是空集（可以不输入，可以是数字、音乐风格），输出是音符（属于序列）3、Sentiment classification 情感分类：输入是评语/一段话（属于序列）">
<meta property="og:type" content="article">
<meta property="og:title" content="DL_RNN">
<meta property="og:url" content="http://yoursite.com/2019/07/29/DL-RNN/index.html">
<meta property="og:site_name" content="MR.C">
<meta property="og:description" content="Sequence Model 序列模型（包括RNN）：1、Speech Recognition 语音识别：输入一段语音，输出英文句子（输入输出都属于Sequence Data序列数据）2、Music generation 音乐生成：输入可以是空集（可以不输入，可以是数字、音乐风格），输出是音符（属于序列）3、Sentiment classification 情感分类：输入是评语/一段话（属于序列）">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/17.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/18.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/19.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/20.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/21.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/22.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/23.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/24.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/25.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/26.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/27.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/28.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/29.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/30.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/31.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/32.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/33.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/34.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/35.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/36.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/37.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/38.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/39.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/40.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/41.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/42.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/43.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/44.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/45.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/46.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/47.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/48.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/49.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/50.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/51.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/52.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/53.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/54.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/55.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/56.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/57.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/58.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/59.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/60.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/61.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/62.png">
<meta property="og:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/63.png">
<meta property="og:updated_time" content="2019-07-29T06:48:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DL_RNN">
<meta name="twitter:description" content="Sequence Model 序列模型（包括RNN）：1、Speech Recognition 语音识别：输入一段语音，输出英文句子（输入输出都属于Sequence Data序列数据）2、Music generation 音乐生成：输入可以是空集（可以不输入，可以是数字、音乐风格），输出是音符（属于序列）3、Sentiment classification 情感分类：输入是评语/一段话（属于序列）">
<meta name="twitter:image" content="https://github.com/soloistben/images/raw/master/deeplearning_image/17.png">
  
    <link rel="alternate" href="/atom.xml" title="MR.C" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">MR.C</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-DL-RNN" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/29/DL-RNN/" class="article-date">
  <time datetime="2019-07-29T01:22:01.000Z" itemprop="datePublished">2019-07-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      DL_RNN
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="Sequence-Model-序列模型（包括RNN）："><a href="#Sequence-Model-序列模型（包括RNN）：" class="headerlink" title="Sequence Model 序列模型（包括RNN）："></a>Sequence Model 序列模型（包括RNN）：</h4><p>1、<strong>Speech Recognition 语音识别</strong>：输入一段语音，输出英文句子（输入输出都属于Sequence Data序列数据）<br>2、<strong>Music generation 音乐生成</strong>：输入可以是空集（可以不输入，可以是数字、音乐风格），输出是音符（属于序列）<br>3、<strong>Sentiment classification 情感分类</strong>：输入是评语/一段话（属于序列），输出是衡量情感的标记<br>4、<strong>DNA Squence analysis DNA序列分析</strong>：输入给定的DNA序列，输出在DNA上标记匹配某种蛋白质的<br>5、<strong>Machine Transaction 机器翻译</strong>：输入英语一句话，输出中文的翻译<br>6、<strong>Video Activity Recognition 视频动作识别</strong>：输入以帧单位的视频，输出描述语句<br>7、<strong>Name Entity Recognition 命名实体识别</strong>：输入一句话，输出在句子中识别到的名字（常用于搜索引擎识别特殊名词）<br>8、在序列模型训练中，有输入输出都是序列数据（可能等长，可能类型不同），也有仅输入或输出才是序列模型，<br>9、命名实体识别在输入句子中，以每个单词为单位，<span style="border-bottom:2px dashed red;">输出一维向量，匹配位置，是名字的标记1，否则标记0（用X&lt;t&gt;来表示单词所在时序序列，Tx表示输入的序列长度，Ty表示输出的序列长度）</span>（这个例子也属于<strong>NLP（Natural Language Processing自然语言处理）</strong>）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/17.png" alt="image"><br>10、NLP中，首要解决的是怎样表示序列里单独的单词，然后制作一个单词表/字典（在商用中字典单词经常会有3w到5w，甚至10w、100w+）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/18.png" alt="image"><br>11、在输入句子序列中，<span style="border-bottom:2px dashed red;">字典个数=每个向量的维度</span>（用one-hot的方式标记向量，用1标出在字典的位置，其他为0，一维向量）<span style="border-bottom:2px dashed red;">（若是遇到不再字典的单词，就创建一个叫做Unknown Word的伪造单词，来表示不再字典的单词）</span><br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/19.png" alt="image"></p>
<h4 id="Recurrent-Neural-Network-RNN"><a href="#Recurrent-Neural-Network-RNN" class="headerlink" title="Recurrent Neural Network RNN:"></a>Recurrent Neural Network RNN:</h4><p>1、若是用传统的神经网络，输入x则全是one-hot的向量，而且维度会很大，输出也相同；缺点是在不同例子中可以有不同长度，Tx与Ty不一定相等，并且<span style="border-bottom:2px dashed red;">从文本位置上学到的特征并没有共享使用（若是一个人名首次被识别人名之后，在第二处，直接就可以识别成人名</span>，这才是想要的结果（计算机视觉，就是学习了小部分特征，立马推广到图片的其他地方））<br>2、<span style="border-bottom:2px dashed red;">RNN：由左到右，每次执行都添加如激活值a[i]（第一个a[0]一般初始化为0，作为伪激活），每一层都会结合上一层所得到的激活值（代表前面所有层的信息）一起预测出y，则每一层都有了联系，参数得到共享</span>（缺点是只得到前面层的信息，得不到后面层的信息，因为有时仅靠前面信息无法推定该词回事人名的单词，会有<strong>Bidirectional Recurrent Neural Network双向循环神经网络（BRNN）</strong>解决该问题）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/20.png" alt="image"><br>3、 <strong>a&lt;t&gt; = g(Waa*a&lt;t-1&gt;+Wax*X&lt;t&gt;+ba); y&lt;t&gt; = g(Wya*a&lt;t&gt;+by)</strong>（W下标，谁在前面就是求谁，在后就要乘以谁）（常用激活函数是tanh/ReLU，通常是<span style="border-bottom:2px dashed red;">tanh</span>，有其他方式可以避免梯度消失问题）（输出部分的激活函数，若是二分问题，则用sigmoid函数）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/21.png" alt="image"><br>4、 设Wa=[Waa Wax]，若Waa维度是(100,100)，Wax是(100,10000)，则Wa是(100,10100)，简化<strong>a&lt;t&gt; = g(Wa[a&lt;t-1&gt;, X&lt;t&gt;]+ba)</strong>，[a&lt;t-1&gt;, X&lt;t&gt;]维度是(10100,100)是a在上部分，X在下部分，结果a&lt;t&gt;维度是(100,100)；简化<strong>y&lt;t&gt; = g(Wy*a&lt;t&gt;+by)</strong>仅有一个下标表示输出什么类型的量<br>5、<strong>RNN反向传播backpropagation through time</strong>：基本与RNN的方向相反（前向传播顺着时间走，反向传播逆着时间走）；<span style="border-bottom:2px dashed red;">某个单词预测的损失函数使用交叉熵损失函数，整个损失值单个单词损失值之和</span><br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/22.png" alt="image"></p>
<h4 id="不同基本模块的RNN："><a href="#不同基本模块的RNN：" class="headerlink" title="不同基本模块的RNN："></a>不同基本模块的RNN：</h4><p>1、Tx=Ty的RNN架构属于多对多类型<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/23.png" alt="image"><br>2、在情感分析的RNN中，输入是一句评语，输出判定正/负面评价（0/1二分类问题），多对一类型则在设计神经网络时，不必像多比多那样每次循环都要输出，仅在最后在输出0/1即可<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/24.png" alt="image"><br>3、在音乐生成的RNN中，输入是空集也可以，输出是一段音乐（序列），一对多类型在设计神经网络时，仅在第一次循环输入，后续循环的输入是上次循环的结果y<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/25.png" alt="image"><br>4、在多对多类型中还有Tx≠Ty的情况，机器翻译就属于其一（每种语言文字单词不全是一对一），则在设计神经网络时，(encode)就先循环输入x，(decode)输入完毕在循环输出y<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/26.png" alt="image"><br>5、一对一结构则是一种标准类型的神经网络，不需要RNN也可以</p>
<h4 id="Language-Model-语言模型："><a href="#Language-Model-语言模型：" class="headerlink" title="Language Model 语言模型："></a>Language Model 语言模型：</h4><p>1、<span style="border-bottom:2px dashed red;">语言模型：输入句子（文本序列 y），进行估计句子中各个单词出现的可能性/概率</span>（学习文字描述风格，在运用风格写文章）（给出部分单词，预测下一个单词）<br>2、训练集要包含 large cropus of English text 很大的英文文本语料库（cropus语料库是自然语言处理中的专业名词，意思是很多很长、用英文句子、组成的文本）<br>3、整个流程：</p>
<ul>
<li>预处理：输入一句话序列(cats average 15 hours of sleep a day)；<strong>tokenize标记化</strong>，将句子中单词转成one-hot向量（字典中的索引），<span style="border-bottom:2px dashed red;">增加一个&lt;EOS&gt;作为句子的结尾</span>，被标记为末尾y&lt;Ty&gt;（若将句号看出标志，其他符号也需要看成标志）；在出现不在字典中的单词时，将其标记问<strong>UNK(Unknown Word)</strong></li>
<li>设计RNN序列概率模型，<span style="border-bottom:2px dashed red;">初始化激活值a&lt;0&gt;和输入值x&lt;1&gt;为零向量，计算出a&lt;1&gt;，再softmax预测出y&lt;1&gt;概率，得出第一个单词的概率；再第二个循环中x&lt;2&gt;=y&lt;1&gt;，重复操作</span>（<strong>通过训练，预测出下一个单词，也就是学习了造句风格，在测试中可以遇到训练过的单词，会更多概率选中与风格相匹配的单词</strong>）；第一层算出概率P(y&lt;1&gt;)，第二层在第一层基础上算出概率P(y&lt;2&gt;|y&lt;1&gt;)，第三层则是P(y&lt;3&gt;|y&lt;1&gt;,y&lt;2&gt;)…最后<strong>P(y&lt;1&gt;,y&lt;2&gt;,y&lt;3&gt;)=P(y&lt;1&gt;)P(y&lt;2&gt;|y&lt;1&gt;)P(y&lt;3&gt;|y&lt;1&gt;,y&lt;2&gt;)</strong><br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/27.png" alt="image"></li>
<li><strong>Sampling novel sequences对新序列进行采样</strong>：在训练序列模型之后，一个非正式的方法（对序列采样）可以得知这个模型学习了什么；<span style="border-bottom:2px dashed red;">对训练得到的概率分布P(y&lt;1&gt;,y&lt;2&gt;,…,y&lt;Tx&gt;)进行采样，来生成一个新的单词序列；首先初始化激活值a&lt;0&gt;和输入值x&lt;1&gt;为零向量，第一层softmax预测到的时所有单词作为第一个单词概率分布，然后进行随机采样（用np.random.choice），将第一层得到的y\<1>输出到第二层，若第一个单词选择了“the”，则第二层计算出在“the”情况下，下一个单词概率，然后再次随机采样，一直循环、采样到结束</1></span>（有可能会出现UNK，所以在采用时拒绝出现未录入字典的单词，直到不是UNK的单词）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/28.png" alt="image"></li>
</ul>
<p>4、<strong>Character-level language model 基于字符的语言模型</strong>：将每个单词字母全部拆分训练，优点是不会出现UNK，缺点是会得到太多太长的序列（一般一个句子就10~20个单词）不利于<strong>捕捉句子间的依赖关系</strong>（句子较前部分预测句子较后部分），并且计算成本高<br>5、NLP趋势是使用<strong>word level language model基于词汇的语言模型</strong>，（在计算能力好的情况下，处理大量未知文本或者专业词汇，使用基于字符的语言模型会更好）</p>
<h4 id="梯度消失："><a href="#梯度消失：" class="headerlink" title="梯度消失："></a>梯度消失：</h4><p>1、RNN常用tanh激活函数，因而存在有梯度消失问题，影响反向传播<br>2、基础的RNN仍是<span style="border-bottom:2px dashed red;">不擅长于捕捉长期依赖效应</span>（主语与谓语相隔较远时，时态和单双数的变化，类似的长期依赖），这需要在RNN对主语的<strong>长期记忆</strong>，才能在后面对谓语有联系<br>3、基础的RNN模型会有很多局部影响，<span style="border-bottom:2px dashed red;">比如y&lt;3&gt;就会受到其附近的值影响，在后面的值很难受到前面的影响，这个区域都很难反向传播到序列前面部分，因此神经网络很难调整前面的计算（缺点）</span><br>4、RNN也会出现梯度爆炸，相对容易发现，会直接让神经网络崩溃，参数数值会很大，甚至NaN，溢出；解决方法：<strong>gradient clipping梯度修剪</strong>（观察梯度向量，若其大于某个threshold阈值，缩放梯度向量，保证它不会太大，这就是最大值修剪）</p>
<h4 id="Gated-Recurrent-Unit-GRU门控循环单元："><a href="#Gated-Recurrent-Unit-GRU门控循环单元：" class="headerlink" title="Gated Recurrent Unit GRU门控循环单元："></a>Gated Recurrent Unit GRU门控循环单元：</h4><p>1、GRU能让RNN在深层网络中捕捉依赖关系，解决梯度消失问题<br>2、RNN中隐藏单元的可视化<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/29.png" alt="image"><br>3、GRU加入新变量c表示memory cell细胞，记忆细胞（在后面动词看到c时会知道主语是单数复数）：在时间t处，c&lt;t&gt;=a&lt;t&gt;（但在LSTMs他俩不相等）<strong>用c~&lt;t&gt; = tanh(Wc[c&lt;t-1&gt;,x&lt;t&gt;+bc)代替了c&lt;t&gt;</strong><br>4、GRU中心思想时，有个门<strong>Γu = sigmoid((Wu[c&lt;t-1&gt;,x&lt;t&gt;+bu)</strong>（Γ 范围是0到1，u代表更新gate，sigmoid的输出范围是[0,1]）<br>5、用c~更新c的等式，然后<span style="border-bottom:2px dashed red;">Γ 决定是否要更新它</span>（假设c&lt;t&gt;=1时表示单数，0表示复数，经过中间隔着很久，到达动词，c&lt;t&gt;仍是等于1，则动词显示单数；Γu 就决定什么时候去更新c&lt;t&gt;这个值）<strong>c&lt;t&gt; = Γu*c~&lt;t&gt; + (1-Γu)*c&lt;t&gt;</strong>（元素对应乘积）（<span style="border-bottom:2px dashed red;">当Γu=1时，c&lt;t&gt;=1，对于主谓语之间的语句 Γu=0，也就是c&lt;t&gt;=c&lt;t-1&gt;，不用进行更新</span>）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/30.png" alt="image"><br>6、因为sigmoid的值，Γu很容易取到0，则c&lt;t&gt;一直维持值不变，因为Γ很接近0，可能是0.000001，c&lt;t&gt;不变，a&lt;t&gt;值也维持不变，这就不会出现梯度消失了<br>7、c&lt;t&gt;可以是个向量，若有100个隐含依赖，则可以是100维，Γ也是相同维度，就是100bit的向量（里面几乎全是0或者1）（Γ不会确切的等于0或者1，会是0到1的中间值，为了理解可以当成0和1）<br>8、完整的GRU公式（会多一个Γr相关门）（GRU和LSTM都十分常用）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/31.png" alt="image"></p>
<h4 id="Long-Short-Term-Memory-LSTM长短期记忆网络："><a href="#Long-Short-Term-Memory-LSTM长短期记忆网络：" class="headerlink" title="Long Short-Term Memory LSTM长短期记忆网络："></a>Long Short-Term Memory LSTM长短期记忆网络：</h4><p>1、比GRU更加有效，是比GRU更通用更强<br>2、在LSTM中得公式，</p>
<ul>
<li>c~&lt;t&gt; = tanh(Wc[a&lt;t-1&gt;,x&lt;t&gt;+bc)</li>
<li>Γu = sigmoid((Wu[a&lt;t-1&gt;,x&lt;t&gt;+bu)    update gate</li>
<li>Γf = sigmoid((Wf[a&lt;t-1&gt;,x&lt;t&gt;+bf)    forget gate</li>
<li>Γo = sigmoid((Wo[a&lt;t-1&gt;,x&lt;t&gt;+bo)     output gate</li>
<li>c&lt;t&gt; = Γu*c~&lt;t&gt; + Γf*c&lt;t-1&gt;（Γf代替1-Γu）</li>
<li>a&lt;t&gt; = Γo*tanh(c&lt;t&gt;)<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/32.png" alt="image"><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/33.png" alt="image"></li>
</ul>
<p>3、设置了forget gate和update gate，则LSTM很容易把c&lt;0&gt;一直传递下去<br>4、在三种gate的计算下，只需要a&lt;t-1&gt;和x&lt;t&gt;，也可以加入c&lt;t-1&gt;，这称为<strong>peephole connection窥视孔连接</strong>（则gate的值也由记忆细胞的值一同决定）<br>5、GRU实在LSTM中做出的简化，GRU设计更简单，只有两个gate，容易创建更大规模更深的网络</p>
<h4 id="Bidirectionnal-RNN-双向RNN："><a href="#Bidirectionnal-RNN-双向RNN：" class="headerlink" title="Bidirectionnal RNN 双向RNN："></a>Bidirectionnal RNN 双向RNN：</h4><p>1、因为单向的 RNN中的单个单词只被其前面的单词所影响，但很多情况影响其的意义来源于后面的内容，因此需要双向RNN<br>2、BRNN，也是一个Acyclic graph无环图，正反向独立运行，（正反向前向传播均属于是前向传播）（可以由前后内容一同判断一个单词）缺点是，<span style="border-bottom:2px dashed red;">需要完整的序列才能预测任意位置，例如做语音识别，需要等这个人把话说完才能进行识别</span><br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/34.png" alt="image"><br>3、<strong>y&lt;t&gt; = g(Wy[a→&lt;t&gt;,a←&lt;t&gt;]+by)</strong></p>
<h4 id="Deep-RNNs"><a href="#Deep-RNNs" class="headerlink" title="Deep RNNs:"></a>Deep RNNs:</h4><p>1、在标准的RNN上，垂直方向多加三趟循环，加上水平时间线上输入x<tx>，已经是很深层了（与卷积100层不一样），会有很多隐含层，计算量十分大<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/35.png" alt="image"><br>2、a[2]&lt;3&gt; = g(Wa[2][a[2]&lt;2&gt;, a[1]&lt;3&gt;]+ba[2])<br>3、第1层有Wa[1]、ba[1]；第2层有Wa[2]、ba[2]；第3层有Wa[3]、ba[3]</tx></p>
<h4 id="Word-Representation-词汇表征："><a href="#Word-Representation-词汇表征：" class="headerlink" title="Word Representation 词汇表征："></a>Word Representation 词汇表征：</h4><p>1、<strong>Embedding 词嵌入</strong>：语言表示的一种方式，<span style="border-bottom:2px dashed red;">可以让算法自动的理解一些类似的词</span>（比如 男人女人、国王王后）（意思是将众多的单词按特征归类）<br>2、通过词嵌入可以构建NLP应用，即使模型的训练集相对小也可以（需要通过一些方法消除词嵌入的偏差）<br>3、用one-hot向量表示单词在字典的位置，会把单词都独立起来，这样泛化能力不强（<span style="border-bottom:2px dashed red;">可以通过300个特征来联系这些单词，但是实际上联系效果还是不够</span>）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/36.png" alt="image"><br>4、<strong>特征化</strong>：可以将300维的特征向量嵌入到二维空间，即可可视化了（常用可视化算法是t-SNE算法，非线性）；可以更直观发现特征相似的词都聚集在一起<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/37.png" alt="image"><br>5、<strong>命名实体识别词嵌入的迁移学习</strong>：在大量无标签文本中学习大量词嵌入（也可以下载已训练好的模型，则可以将自己少量的训练集迁移学习，除非训练集很大，否则不需要再次调整词嵌入，直接使用就好）<br>6、词嵌入的运用十分广泛（<strong>named entity recognition命名实体识别</strong>、<strong>text summarization文本摘要</strong>、<strong>co-reference resolution 文本解析</strong>、<strong>parsing指代消解</strong>）；在语言模型之类的训练，则较少用到（因为会有大量数据）<br>7、词嵌入特征是能帮助实现<strong>analogy reasoning类比推理</strong>（虽然没有在NLP中着重运用，但能让人看到词嵌入干了什么，能干什么）；当男人能推出女人时，国王也能推出女王，得出他们差别都在性别（<strong>Eman-Ewomen ≈ Eking-Equeen</strong>）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/38.png" alt="image"><br>8、求<strong>Ew</strong>(Equeen)：<strong>argmax sim(Ew, Eking-Eman+Ewomen)</strong> 相似最大化；通过方程找导最理想结果（准确率一般只有30%~70%）（常用的similarity function相似度函数时<strong>cosine similarity余弦相似度 sim(u,v)=(u^T * v)/(||u|| ||v||)，就是求u、v的俩向量的夹角Φ余弦值</strong>（cos函数中，Φ=0时，cos值是1；Φ=2PI 时，cos值是-1；就是两者越是相似，角度Φ越小，越接近1，越大则不相似则会接近-1））（<span style="border-bottom:2px dashed red;">相同关系的推断：线性，同特征的推断会使向量趋向平行</span>）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/39.png" alt="image"><br>9、还可以用<strong>平方距离/欧式距离||u-v||^2</strong>求差异表示相似度<br>10、学习词嵌入就是学习一个嵌入矩阵，嵌入矩阵E，维度(300,1000)，与one-hot向量o，维度(1000,1)；<strong>E·o=e</strong>（o向量在E中的<strong>嵌入向量e</strong>(300,1)）（但不常用矩阵乘积的方法找e，计算量太大，矩阵乘积慢，会有单独函数方法来直接找到E中的哪一列）<br>11、词嵌入的NLP过程，求得每个嵌入向量e，最终汇聚于全连接层和softmax输出，做出多个单词的概率计算，最高概率则是预测单词（也可以仅看前4个单词即可推出，适当减少参数；或者仅提供其前面的/附近的一个单词也可）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/40.png" alt="image"><br>12、<strong>Word2Vec算法的skip-gram模型</strong>：（用于学习词嵌入更高效）抽取上下文单词于目标词匹配，来构造一个监督学习问题（Content c “orange” -&gt; Target t “juice”）（<strong>o_c -&gt; E -&gt; e_c -&gt; softmax -&gt; y^</strong>）（softmax：<strong>p(t|c)=(e^(θt^T * e_c))/(Σj e^(θj^T·e_c)</strong>)（θt是一个输出t的参数））（softmax损失函数：<strong>L(y^,y)=-Σi yi log y^</strong>）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/41.png" alt="image"><br>13、关键的p(t|c)中分母运算太大使得操作变慢；解决方法：使用hierarchical分级的softmax分类器（类似折中查找一样，每次二分为一查找，提高速度（也类似哈夫曼树，使用频率高的词靠近root））<br>14、<strong>Negative Sample 负采样</strong>：（与skip-gram模型做的相类似，但效率会更好）构造新的监督学习，给定一对单词，去预测是否是一对content-target的组合（<strong>context：orange-juice 输出target 1属于正样本；context：orange-king 输出target 0属于负样本</strong>）（k次随机在字典中寻找词与orange匹配得出负样本，提供作为训练集）（数据集小的话k一般取5~20；数据集大k选2~5即可）；可以使用<strong>logistic回归模型</strong>，p(y=1|c,t)=sigmoid(θt^T·e_c)；在整个训练中，训练一个正样本、随机k个负样本，就不需要每次在softmax中分母运算高纬度求和<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/42.png" alt="image"><br>15、在负采样中负样本的word如何选？推出该公式用于选取负样本的word（对词频的3/4次方，再求在总和的比例）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/43.png" alt="image"><br>16、（难）<strong>GloVe word vector 词向量算法</strong>：用词表示全局变量，明确context-target的关系Xij（i、jb表示两个词，Xij=Xji（若i、j相邻，则不符合这个对称等式）可将i、j定义为两个位置相近的单词，假设左右各10词的距离）；Xij可获取单词i、j出现位置相近时或者彼此接近时的频率的计数器<br>17、（难）<strong>GloVe’s Model</strong>：最小化它们的差值 <strong>minimize=ΣiΣj f(Xij)((θi^T·ej+bi+bj-logXij)^2</strong>；表示两个单词关系多紧密（防止Xij=0，导致无穷大，需添加一个weighting term加权项f(Xij)项，当Xij=0，f(Xij)=0）；<span style="border-bottom:2px dashed red;">不给频繁词过大的权重，不给少用词太小的权重</span>；θ和e是对称的，将其颠倒或排序，都可以输出最佳结果；训练方法是将他们一致地初始化，然后梯度下降来最小化输出，当每个词处理完之后，取平均值（e(find)=(e_w+θ_w)/2）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/44.png" alt="image"><br>18、<strong>Sentiment classification情感分析</strong>：分细一段评语，判断是否喜欢讨论的东西；这个任务的标记训练集可能没有那么多，可用词嵌入；可用于收集消费者的评价<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/45.png" alt="image"><br>19、训练嵌入矩阵E会很大维度（若在很大训练集上训练E，则会学到很多知识）；在特征向量求得需要平均化在送入softmax；<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/46.png" alt="image"><br>20、只把词的特征向量，加起来，可能就理解不了“反话”，则需要RNN<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/47.png" alt="image"><br>21、<strong>debiasing word embedding 词嵌入消除偏见</strong>：在使用词嵌入时需要减少或者消除词嵌入（一个完成词嵌入可能会输出Man:Computer_Programmer as Woman:Homemake / father:doctor as mother:nurse这种性别歧视的话语）；<span style="border-bottom:2px dashed red;">根据训练模型使用的文本，词嵌入能反映出性别、种族、年龄、性取向等的这些偏见</span>（这些偏见都跟社会经济状态相关，机器学习作出决策时不应该存在偏见）<br>22、步骤：1）辨别出想要减少的或者消除的特定偏见趋势（将(e_he - e_she)和(e_male - e_female)这类的男女性别的差值求和再简单取平均值）；2）neutralize step中和步，对那些定义不确切的词，可以将其处理下，避免偏见；3）Equalize pairs 均衡步，类似girl和boy能够有一致的相似度（距离中立词语能有相等距离）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/48.png" alt="image"></p>
<h4 id="Basic-Models-基础模型："><a href="#Basic-Models-基础模型：" class="headerlink" title="Basic Models 基础模型："></a>Basic Models 基础模型：</h4><p>1、<strong>seq2seq的机器翻译（法语转英语）</strong>：将法语句子序列转成输入向量x，英语句子为y；<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/49.png" alt="image"><br>输入需要先经过一个<strong>encoder network编码网络</strong>（属于RNN，隐含单元可以是GRU/LSTM）（<span style="border-bottom:2px dashed red;">输入法语，在输出一个能代替法语的 向量，更好进行训练</span>）；在后面可以建立一个<strong>decoder network解码网络</strong>（输出英语，直到输出结束标志）（这一部分RNN与语言模型的RNN基本一致）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/50.png" alt="image"><br>2、<strong>Image captioning图像描述</strong>（用一句话描述图片）：在卷积神经网络（AlexNet）中先识别图片（可以算作图像的编码网络（得到一个4096的一维向量）），然后用RNN生成图片的描述（作为解码网络）<br>3、可以将机器翻译称为有条件的语言模型<strong>P(y&lt;1&gt;,y&lt;2&gt;,…,y&lt;Ty&gt;|x)</strong>；<span style="border-bottom:2px dashed red;">在机器翻译可能会翻译出多条句子，虽然没错但不是最好的翻译</span>（最好的翻译结果句子的P(y|x)是最高的），则需要一种算法将找到合适的y值，再将其最大化（常用算法为<strong>Beam Search束搜索</strong>）（Greedy search贪心搜索算法不可用，最常用的搭配不见得是最好的翻译结果，并且每个词都需要遍历所有去寻找最好的，计算量是字典总数的指数级别）<br>4、<strong>Beam Search集束搜索</strong>：</p>
<ul>
<li>首先在解码网络中，需要在字典10000的单词中，挑选出输出的第一个单词P(y&lt;1&gt;|x)，会考虑选多个的单词（<span style="border-bottom:2px dashed red;">参数B，称为beam width集束宽，B=3则一次会考虑三个单词</span>）将所挑选的单词概率存入计算机内存里；</li>
<li><p>在所选的三个单词，分别再其基础上选择第二个单词P(y&lt;2&gt;|x,y&lt;1&gt;)，<span style="border-bottom:2px dashed red;">但最主要是找到最大概率<strong>P(y&lt;1&gt;,y&lt;2&gt;|x) = P(y&lt;1&gt;|x) * P(y&lt;2&gt;|x,y&lt;1&gt;)</strong></span>；第二步就有30000种可能了，然后在这30000可能中找出3个最高的概率的y&lt;1&gt;,y&lt;2&gt;继续下个30000的概率选择；主要乘积概率公式如下：<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/51.png" alt="image"></p>
</li>
<li><p>重复类似第二步的操作，每一步增加一个单词，直至识别结束符号；当B=1时，就变成了贪婪搜索</p>
</li>
</ul>
<p>5、<strong>Length normalization 长度归一化</strong>：对集束搜索的稍微调整；因为通过beam search公式所求概率通常小于1，多次小于1的概率乘积，会变得很小很小，导致数值下溢，计算机精度不够无法精准存储；<span style="border-bottom:2px dashed red;">改造公式为对数的求和，更加稳定，不容易出现四舍五入的误差避，免数值下溢（对数函数单调递增，所以最大化logP(y|x)与最大化P(y|x)是一回事）</span>；<br>6、（因为每次都会乘以小于1的概率，所以也会偏向更少数量的输出）<span style="border-bottom:2px dashed red;">因为最短也不一定是最好的输出，所以不再最大化概率了，改为归一化，求概率对数的平均值</span>；在取平均数时，如何选择分母才会更好，在分母设置参数α，Ty^a作为分母会更柔和一点，α可以设置为0.7；α=0则等于没有归一化，α=1则等于完全用长度来归一化；用调整后的α会得到更好的结果<br>7、对于B的选择，一般越多还是越好，但过多计算成本就会变高；B很大的情况：会得到更好的结果，计算会慢一些，占用内存大；B很小的情况：结果不会很好，但计算快，占用内存少；<span style="border-bottom:2px dashed red;">一般在实际使用会设置B=10</span>；设置为100就太大了，但在科研需要更好的效果则会设置成1000或者3000<br>8、运用广度优先搜索或者深度优先搜索可能会比集束搜索速度更快，但不能保证一定找到最大化的精准的最大值<br>9、误差分析可以节省时间，用更多时间投入更有用的工作<br>10、集束搜索算法是一种<strong>approximate search近似搜索算法/heuristic search启发式搜索算法</strong>，不直接输出最好的句子，而是记录多个好句子，再输出最好的<br>11、人工翻译的句子记为y*、RNN输出结果记为y^；人工翻译比RNN输出要好的前提下，对比P(y*|x)和P(y^|x)（忽略归一化复杂情况下）</p>
<ul>
<li>case1：P(y*|x)&gt;P(y^|x)，则beam search出问题了（加大B），没有找到更大的y^</li>
<li>case2：P(y*|x)&lt;=P(y^|x)，则是RNN出问题了（加深网络），y*翻译试比y^好的，但RNN算出P(y*|x)&lt;=P(y^|x)</li>
</ul>
<p>12、持续多次句子翻译的对比P(y*|x)和P(y^|x)，出现最多错的就是最主要误差问题</p>
<h4 id="Bleu-score："><a href="#Bleu-score：" class="headerlink" title="Bleu score："></a>Bleu score：</h4><p>1、用于代替人类去评估机器翻译结果，衡量准确性（给定一个翻译结果，计算出一个分数，接近人类的翻译就高分）；衡量机器翻译质量的方法之一是<span style="border-bottom:2px dashed red;">观察输出结果的每一个词，看其是否出现在人工翻译参考当中</span>（精确度）（但是出现个别情况，输出所有单词一样，并且其都在人工翻译中出现，会出现精度很好，但翻译出的句子不行）；改良后的方法：<span style="border-bottom:2px dashed red;">记录每一个词在出现在人工翻译中的次数，在多个人工翻译句子里面出现最多次数视为上限，上限为分子，在机器翻译的结果中出现的次数为分母</span>；<strong>体现出翻译结果与人工翻译的重叠层度</strong>（若是与人工翻译一致，则P=1.0）（可以下载已有的模型）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/52.png" alt="image"><br>2、<strong>Bleu score on brigrams（二元组）（相邻两个单词）</strong>：（unigrams一元组）（也会有trigrams三元组）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/53.png" alt="image"><br>3、一元组精度公式：<strong>P1=Σ</strong>unigram∈y^ <em> <strong>Count</strong>clip<strong>(unigram) / Σ</strong>unigram∈y^ </em> <strong>Count(unigram)</strong><br>4、n元组精度公式：<strong>Pn=Σ</strong>n-gram∈y^ <em> <strong>Count</strong>clip<strong>(n-gram) / Σ</strong>n-gram∈y^ </em> <strong>Count(n-gram)</strong><br>5、结合Bleu score，采用BP（<strong>brevity penalty简短惩罚</strong>）的惩罚因子作为调整因子，<strong>BPexp(1/4 Σ4 Pn)</strong>（对P1、P2、P3、P4取均值）；<span style="border-bottom:2px dashed red;">若是输出一个很短的翻译则会得到很高的精确度，但简短的输出也不一定是最好</span>；机器翻译长度大于人工翻译，BP=1<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/54.png" alt="image"></p>
<h4 id="（难）Attention-Model-注意力模型："><a href="#（难）Attention-Model-注意力模型：" class="headerlink" title="（难）Attention Model 注意力模型："></a>（难）Attention Model 注意力模型：</h4><p>1、在翻译一段文本中，人类大部分是翻译一部分，再翻译下一部分，而不是看完全部，再靠记忆去由零开始翻译<br>2、Bleu score在短文翻译和长达30字以上的文本翻译都会比较难，所以分数较低<br>3、注意力模型就会让其变得更像人类一样翻译文本，在长文本中表现良好<br>4、<span style="border-bottom:2px dashed red;">利用BRNN，但每层的输出并不会直接输出翻译结果，而是输出<strong>α&lt;t,t’&gt;“注意力权重”</strong>用于接入新的RNN的<strong>S&lt;t&gt;“注意力权重集”</strong>（注意力权重则是一个注意力权重集对BRNN这层的所需要的注意力），S&lt;t&gt;的输入会是对应单词和其上下文单词（多个输入），再逐个输出翻译的单词</span><br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/55.png" alt="image"><br>5、上下文的定义是<span style="border-bottom:2px dashed red;">被注意力权重除权的不同步时间中的特征值</span>；BRNN多个输出α&lt;t,t’&gt;相加得出<strong>c&lt;t&gt;</strong>，c&lt;t&gt;在统一输入注意力权重集（<strong>c&lt;t&gt;=Σα&lt;t,t’&gt;*a&lt;t’&gt;</strong>）（<strong>Σα&lt;t,t’&gt;=1</strong>）（用softmax来确保这些权重加起来等于1）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/56.png" alt="image"><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/57.png" alt="image"><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/58.png" alt="image"><br>6、如果想要决定花多少注意力在t’的激活值上，很大程度取决于上一个时间步的s&lt;t-1&gt;的隐藏状态的激活值<br>7、缺点是算法复杂度是O(n^3)，总参数个数会是Tx*Ty，但是一部分一部分翻译的话，这个消耗还是很可接受<br>8、注意力模型还被应用于将任何形式的时间表达方法转化成标准时间显示方式<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/59.png" alt="image"><br>9、注意力权重的可视化，需要更多注意力的色块会更亮<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/60.png" alt="image"></p>
<h4 id="Speech-Recognition-语音识别："><a href="#Speech-Recognition-语音识别：" class="headerlink" title="Speech Recognition 语音识别："></a>Speech Recognition 语音识别：</h4><p>1、seq2seq在音频上的应用（输入音频，输出文本）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/61.png" alt="image"><br>2、音频数据的常见预处理步骤：运行这个原始的音频片段，然后生成一个<strong>spectrogram声谱图</strong>（不同颜色表示声波能量的大小）；<strong>false blank output伪空白输出</strong>（模仿人耳）也常应用于预处理<br>3、曾经也有人工设计的<strong>phonemes音位</strong>作为基本单元（就是听发音判别单词）<br>4、采用<strong>CTC损失函数（connectionist temporal classification）</strong>来做语音识别；例如”the quick brown fox”一句话十秒，每秒100hz，则有1000层输入（模型较为简单，但很深）；虽然输入有1000，但输出是没有1000，则需要用到CTC，整合输出”ttt__h_eee____ __qq__…”类似的以赫兹输出音频（CTC：将空格之间的重复字符折叠起来成为一个单词）<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/62.png" alt="image"></p>
<h4 id="Trigger-word-detect触发检字："><a href="#Trigger-word-detect触发检字：" class="headerlink" title="Trigger word detect触发检字："></a>Trigger word detect触发检字：</h4><p>1、类似”ok，google！”一样的唤醒语音系统，然后发出一条语音指令，再识别后执行某些事<br>2、设备一直检测着附近的音频，输入音频，提取出音频中的特征，将特征输入RNN，再没有识别到关键字的时候，输出0，检测到关键字时输出1；缺点是0太多了，导致训练集很不平衡；<span style="border-bottom:2px dashed red;">一个暴力解决方法（在输出1后，固定一定时间保持输出1，达到一定平衡）</span>，起码是训练集更加平衡些，更好于训练<br><img src="https://github.com/soloistben/images/raw/master/deeplearning_image/63.png" alt="image"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/29/DL-RNN/" data-id="ck50s01rh0003fjeg8zhtj67w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/19/GNN/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          GNN
        
      </div>
    </a>
  
  
    <a href="/2019/07/19/Blockchain/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Blockchain</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/12/02/Master-Eng/">Master_Eng</a>
          </li>
        
          <li>
            <a href="/2019/11/14/algorithm/">algorithm</a>
          </li>
        
          <li>
            <a href="/2019/08/19/GNN/">GNN</a>
          </li>
        
          <li>
            <a href="/2019/07/29/DL-RNN/">DL_RNN</a>
          </li>
        
          <li>
            <a href="/2019/07/19/Blockchain/">Blockchain</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 (soloistben)<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>